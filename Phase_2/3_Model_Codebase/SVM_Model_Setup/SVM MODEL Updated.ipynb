{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28a52897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./opt/anaconda3/lib/python3.8/site-packages (1.0.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp38-cp38-macosx_10_9_x86_64.whl (9.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.0 MB 1.4 MB/s eta 0:00:01     |████████████▉                   | 3.6 MB 1.3 MB/s eta 0:00:05\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in ./opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.22.4)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.6.2)\n",
      "Installing collected packages: joblib, scikit-learn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.0.1\n",
      "    Uninstalling joblib-1.0.1:\n",
      "      Successfully uninstalled joblib-1.0.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "518191fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f6cc7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Model libraries\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "from sklearn.feature_selection import RFE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9928cd7",
   "metadata": {},
   "source": [
    "### OPENFACE AVERAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a921fd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoName</th>\n",
       "      <th>mean_AU01</th>\n",
       "      <th>mean_AU02</th>\n",
       "      <th>mean_AU04</th>\n",
       "      <th>mean_AU05</th>\n",
       "      <th>mean_AU06</th>\n",
       "      <th>mean_AU07</th>\n",
       "      <th>mean_AU09</th>\n",
       "      <th>mean_AU10</th>\n",
       "      <th>mean_AU11</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_AU28</th>\n",
       "      <th>mean_AU43</th>\n",
       "      <th>mean_anger</th>\n",
       "      <th>mean_disgust</th>\n",
       "      <th>mean_fear</th>\n",
       "      <th>mean_happiness</th>\n",
       "      <th>mean_sadness</th>\n",
       "      <th>mean_surprise</th>\n",
       "      <th>mean_neutral</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trial_lie_001_000</td>\n",
       "      <td>0.559135</td>\n",
       "      <td>0.513050</td>\n",
       "      <td>0.254950</td>\n",
       "      <td>0.413367</td>\n",
       "      <td>0.131757</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.210417</td>\n",
       "      <td>0.106673</td>\n",
       "      <td>0.479506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137724</td>\n",
       "      <td>0.144841</td>\n",
       "      <td>0.034503</td>\n",
       "      <td>0.004511</td>\n",
       "      <td>0.018815</td>\n",
       "      <td>0.346850</td>\n",
       "      <td>0.249029</td>\n",
       "      <td>0.265825</td>\n",
       "      <td>0.080468</td>\n",
       "      <td>lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trial_lie_001_001</td>\n",
       "      <td>0.546610</td>\n",
       "      <td>0.482385</td>\n",
       "      <td>0.292549</td>\n",
       "      <td>0.393281</td>\n",
       "      <td>0.123315</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.182163</td>\n",
       "      <td>0.044325</td>\n",
       "      <td>0.473213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103712</td>\n",
       "      <td>0.110869</td>\n",
       "      <td>0.027199</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.015653</td>\n",
       "      <td>0.453637</td>\n",
       "      <td>0.151641</td>\n",
       "      <td>0.245443</td>\n",
       "      <td>0.100194</td>\n",
       "      <td>lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trial_lie_001_002</td>\n",
       "      <td>0.560753</td>\n",
       "      <td>0.483092</td>\n",
       "      <td>0.291333</td>\n",
       "      <td>0.393530</td>\n",
       "      <td>0.129316</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.184086</td>\n",
       "      <td>0.036360</td>\n",
       "      <td>0.473673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111731</td>\n",
       "      <td>0.127748</td>\n",
       "      <td>0.028358</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.016593</td>\n",
       "      <td>0.468327</td>\n",
       "      <td>0.091021</td>\n",
       "      <td>0.293954</td>\n",
       "      <td>0.094625</td>\n",
       "      <td>lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trial_lie_001_003</td>\n",
       "      <td>0.532220</td>\n",
       "      <td>0.481838</td>\n",
       "      <td>0.321986</td>\n",
       "      <td>0.388174</td>\n",
       "      <td>0.154953</td>\n",
       "      <td>0.126984</td>\n",
       "      <td>0.256083</td>\n",
       "      <td>0.150329</td>\n",
       "      <td>0.478114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153399</td>\n",
       "      <td>0.227434</td>\n",
       "      <td>0.024174</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.013205</td>\n",
       "      <td>0.099999</td>\n",
       "      <td>0.258340</td>\n",
       "      <td>0.403113</td>\n",
       "      <td>0.198486</td>\n",
       "      <td>lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trial_lie_002_000</td>\n",
       "      <td>0.436142</td>\n",
       "      <td>0.412403</td>\n",
       "      <td>0.371331</td>\n",
       "      <td>0.332483</td>\n",
       "      <td>0.242381</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.288108</td>\n",
       "      <td>0.081820</td>\n",
       "      <td>0.473882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086161</td>\n",
       "      <td>0.207142</td>\n",
       "      <td>0.120490</td>\n",
       "      <td>0.027522</td>\n",
       "      <td>0.039825</td>\n",
       "      <td>0.132332</td>\n",
       "      <td>0.517453</td>\n",
       "      <td>0.074959</td>\n",
       "      <td>0.087419</td>\n",
       "      <td>lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>trial_truth_060_000</td>\n",
       "      <td>0.496345</td>\n",
       "      <td>0.485515</td>\n",
       "      <td>0.535118</td>\n",
       "      <td>0.406868</td>\n",
       "      <td>0.251973</td>\n",
       "      <td>0.246032</td>\n",
       "      <td>0.375586</td>\n",
       "      <td>0.317093</td>\n",
       "      <td>0.470617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061832</td>\n",
       "      <td>0.483794</td>\n",
       "      <td>0.317662</td>\n",
       "      <td>0.047535</td>\n",
       "      <td>0.087699</td>\n",
       "      <td>0.050396</td>\n",
       "      <td>0.224306</td>\n",
       "      <td>0.103952</td>\n",
       "      <td>0.168450</td>\n",
       "      <td>truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>trial_truth_060_001</td>\n",
       "      <td>0.422170</td>\n",
       "      <td>0.468637</td>\n",
       "      <td>0.446201</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>0.177772</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.292094</td>\n",
       "      <td>0.330395</td>\n",
       "      <td>0.467192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041104</td>\n",
       "      <td>0.088334</td>\n",
       "      <td>0.256627</td>\n",
       "      <td>0.011986</td>\n",
       "      <td>0.083970</td>\n",
       "      <td>0.062653</td>\n",
       "      <td>0.051118</td>\n",
       "      <td>0.459040</td>\n",
       "      <td>0.074607</td>\n",
       "      <td>truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>trial_truth_060_002</td>\n",
       "      <td>0.515533</td>\n",
       "      <td>0.491938</td>\n",
       "      <td>0.438462</td>\n",
       "      <td>0.551434</td>\n",
       "      <td>0.202776</td>\n",
       "      <td>0.139344</td>\n",
       "      <td>0.341805</td>\n",
       "      <td>0.180777</td>\n",
       "      <td>0.470024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059043</td>\n",
       "      <td>0.132496</td>\n",
       "      <td>0.111543</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.142710</td>\n",
       "      <td>0.088277</td>\n",
       "      <td>0.061379</td>\n",
       "      <td>0.563947</td>\n",
       "      <td>0.026286</td>\n",
       "      <td>truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>trial_truth_060_003</td>\n",
       "      <td>0.469542</td>\n",
       "      <td>0.475879</td>\n",
       "      <td>0.492550</td>\n",
       "      <td>0.457961</td>\n",
       "      <td>0.187666</td>\n",
       "      <td>0.245763</td>\n",
       "      <td>0.367703</td>\n",
       "      <td>0.170327</td>\n",
       "      <td>0.469233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063372</td>\n",
       "      <td>0.142941</td>\n",
       "      <td>0.245029</td>\n",
       "      <td>0.015846</td>\n",
       "      <td>0.144640</td>\n",
       "      <td>0.164392</td>\n",
       "      <td>0.021705</td>\n",
       "      <td>0.363823</td>\n",
       "      <td>0.044565</td>\n",
       "      <td>truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>trial_truth_060_004</td>\n",
       "      <td>0.532738</td>\n",
       "      <td>0.520756</td>\n",
       "      <td>0.499290</td>\n",
       "      <td>0.475737</td>\n",
       "      <td>0.249443</td>\n",
       "      <td>0.198198</td>\n",
       "      <td>0.384727</td>\n",
       "      <td>0.080069</td>\n",
       "      <td>0.469876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049478</td>\n",
       "      <td>0.158766</td>\n",
       "      <td>0.150649</td>\n",
       "      <td>0.049503</td>\n",
       "      <td>0.127929</td>\n",
       "      <td>0.057324</td>\n",
       "      <td>0.019860</td>\n",
       "      <td>0.561616</td>\n",
       "      <td>0.033119</td>\n",
       "      <td>truth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>737 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               VideoName  mean_AU01  mean_AU02  mean_AU04  mean_AU05  \\\n",
       "0      trial_lie_001_000   0.559135   0.513050   0.254950   0.413367   \n",
       "1      trial_lie_001_001   0.546610   0.482385   0.292549   0.393281   \n",
       "2      trial_lie_001_002   0.560753   0.483092   0.291333   0.393530   \n",
       "3      trial_lie_001_003   0.532220   0.481838   0.321986   0.388174   \n",
       "4      trial_lie_002_000   0.436142   0.412403   0.371331   0.332483   \n",
       "..                   ...        ...        ...        ...        ...   \n",
       "732  trial_truth_060_000   0.496345   0.485515   0.535118   0.406868   \n",
       "733  trial_truth_060_001   0.422170   0.468637   0.446201   0.508495   \n",
       "734  trial_truth_060_002   0.515533   0.491938   0.438462   0.551434   \n",
       "735  trial_truth_060_003   0.469542   0.475879   0.492550   0.457961   \n",
       "736  trial_truth_060_004   0.532738   0.520756   0.499290   0.475737   \n",
       "\n",
       "     mean_AU06  mean_AU07  mean_AU09  mean_AU10  mean_AU11  ...  mean_AU28  \\\n",
       "0     0.131757   0.119048   0.210417   0.106673   0.479506  ...   0.137724   \n",
       "1     0.123315   0.076923   0.182163   0.044325   0.473213  ...   0.103712   \n",
       "2     0.129316   0.094017   0.184086   0.036360   0.473673  ...   0.111731   \n",
       "3     0.154953   0.126984   0.256083   0.150329   0.478114  ...   0.153399   \n",
       "4     0.242381   0.111111   0.288108   0.081820   0.473882  ...   0.086161   \n",
       "..         ...        ...        ...        ...        ...  ...        ...   \n",
       "732   0.251973   0.246032   0.375586   0.317093   0.470617  ...   0.061832   \n",
       "733   0.177772   0.228070   0.292094   0.330395   0.467192  ...   0.041104   \n",
       "734   0.202776   0.139344   0.341805   0.180777   0.470024  ...   0.059043   \n",
       "735   0.187666   0.245763   0.367703   0.170327   0.469233  ...   0.063372   \n",
       "736   0.249443   0.198198   0.384727   0.080069   0.469876  ...   0.049478   \n",
       "\n",
       "     mean_AU43  mean_anger  mean_disgust  mean_fear  mean_happiness  \\\n",
       "0     0.144841    0.034503      0.004511   0.018815        0.346850   \n",
       "1     0.110869    0.027199      0.006233   0.015653        0.453637   \n",
       "2     0.127748    0.028358      0.007122   0.016593        0.468327   \n",
       "3     0.227434    0.024174      0.002683   0.013205        0.099999   \n",
       "4     0.207142    0.120490      0.027522   0.039825        0.132332   \n",
       "..         ...         ...           ...        ...             ...   \n",
       "732   0.483794    0.317662      0.047535   0.087699        0.050396   \n",
       "733   0.088334    0.256627      0.011986   0.083970        0.062653   \n",
       "734   0.132496    0.111543      0.005858   0.142710        0.088277   \n",
       "735   0.142941    0.245029      0.015846   0.144640        0.164392   \n",
       "736   0.158766    0.150649      0.049503   0.127929        0.057324   \n",
       "\n",
       "     mean_sadness  mean_surprise  mean_neutral  Label  \n",
       "0        0.249029       0.265825      0.080468    lie  \n",
       "1        0.151641       0.245443      0.100194    lie  \n",
       "2        0.091021       0.293954      0.094625    lie  \n",
       "3        0.258340       0.403113      0.198486    lie  \n",
       "4        0.517453       0.074959      0.087419    lie  \n",
       "..            ...            ...           ...    ...  \n",
       "732      0.224306       0.103952      0.168450  truth  \n",
       "733      0.051118       0.459040      0.074607  truth  \n",
       "734      0.061379       0.563947      0.026286  truth  \n",
       "735      0.021705       0.363823      0.044565  truth  \n",
       "736      0.019860       0.561616      0.033119  truth  \n",
       "\n",
       "[737 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the final csv\n",
    "folder_path = \"/Users/shreya/606 Capstone/VideoChunks_1 /OpenFace_Final/Final.csv\"\n",
    "video = pd.read_csv(folder_path)\n",
    "video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7fa5553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for and delete null values\n",
    "video.dropna()\n",
    "video = video.drop('VideoName', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e546279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "lie = video.loc[video['Label'] == 'lie']\n",
    "truth = video.loc[video['Label'] == 'truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a777cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "lie_X = lie.drop('Label', axis=1)\n",
    "lie_y = lie['Label'].map({'lie':1,'truth':0})\n",
    "truth_X = truth.drop('Label', axis=1)\n",
    "truth_y = truth['Label'].map({'lie':1,'truth':0})\n",
    "\n",
    "lieX_train, lieX_test, liey_train, liey_test = train_test_split(lie_X, lie_y, test_size=0.2)\n",
    "truthX_train, truthX_test, truthy_train, truthy_test = train_test_split(truth_X, truth_y, test_size=0.2)\n",
    "\n",
    "framesX_train = [lieX_train, truthX_train]\n",
    "framesX_test = [lieX_test, truthX_test]\n",
    "framesy_train = [liey_train, truthy_train]\n",
    "framesy_test = [liey_test, truthy_test]\n",
    "\n",
    "X_train = pd.concat(framesX_train)\n",
    "X_test = pd.concat(framesX_test)\n",
    "y_train = pd.concat(framesy_train)\n",
    "y_test = pd.concat(framesy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba8f45e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an SVM object\n",
    "svm = SVC(kernel='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8c46706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the SVM model to the training data\n",
    "svm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7521050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classes of the test data\n",
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16839516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7027027027027027\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb4c4021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50, 20],\n",
       "       [24, 54]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ef325de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot(colorbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab2bdab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7464788732394366\n",
      "Recall: 0.6794871794871795\n"
     ]
    }
   ],
   "source": [
    "#precision and recall factor\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421a4749",
   "metadata": {},
   "source": [
    "#### HYPER PARAMETER TUNING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77612636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameter grid to search over\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100], \n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], \n",
    "    'gamma': ['scale', 'auto', 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Create SVM estimator object\n",
    "svm = SVC()\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38ec8732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 10, 'gamma': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Create variables for best model and best hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d64492e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8648648648648649\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SVM with the chosen hyperparameters\n",
    "svm_hyp=SVC(C=10, gamma=10, kernel='rbf')\n",
    "\n",
    "# Train the SVM on the training data\n",
    "svm_hyp.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the SVM on the testing data\n",
    "score = svm_hyp.score(X_test, y_test)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b793edf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7297297297297297\n",
      "Recall: 0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "#precision and recall factor\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d35c10",
   "metadata": {},
   "source": [
    "first load the dataset and split it into input features X and target variable y. We then create an SVM model with linear kernel and use RFE to select the top 5 features. We obtain the feature ranking using rfe.ranking_, which assigns a rank to each feature based on its importance. Finally, we plot the feature ranking using a bar chart with Plotly Express."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba64e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an SVM model with linear kernel\n",
    "model = SVC(kernel='linear')\n",
    "\n",
    "# Select the top 5 features using RFE\n",
    "rfe = RFE(model, n_features_to_select=5)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get the feature ranking\n",
    "feature_ranking = pd.Series(rfe.ranking_, index=X_train.columns)\n",
    "\n",
    "# Plot a bar chart of the feature ranking\n",
    "fig = px.bar(feature_ranking,\n",
    "             color=feature_ranking.values,\n",
    "             labels={'index':'Feature Name','value':'Ranking'},\n",
    "             height=400,\n",
    "             title=\"Feature Ranking\",\n",
    "             color_continuous_scale='Blugrn')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8543cf69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: py-feat 0.5.1\n",
      "Uninstalling py-feat-0.5.1:\n",
      "  Would remove:\n",
      "    /Users/shreya/opt/anaconda3/lib/python3.8/site-packages/feat/*\n",
      "    /Users/shreya/opt/anaconda3/lib/python3.8/site-packages/py_feat-0.5.1.dist-info/*\n",
      "Proceed (y/n)? "
     ]
    }
   ],
   "source": [
    "!pip install py-feat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb679d3",
   "metadata": {},
   "source": [
    "### OPENFACE INDIVIDUAL FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e479d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the train and test csv files\n",
    "train_path = \"/Users/shreya/606 Capstone/train_DARE_3.csv\"\n",
    "train_file = pd.read_csv(train_path)\n",
    "test_path = \"/Users/shreya/606 Capstone/test_DARE_3.csv\"\n",
    "test_file = pd.read_csv(test_path)\n",
    "\n",
    "train_file[\"video_name\"] = train_file[\"video_name\"].str[:-4]\n",
    "test_file[\"video_name\"] = test_file[\"video_name\"].str[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48096967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>video_path</th>\n",
       "      <th>duration_in_seconds</th>\n",
       "      <th>FPS</th>\n",
       "      <th>total_frame_count</th>\n",
       "      <th>label</th>\n",
       "      <th>video_root_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trial_lie_039_006.mp4</td>\n",
       "      <td>./data/Video_chunks/Video_chunks\\trial_lie_039...</td>\n",
       "      <td>4.02</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>108.540000</td>\n",
       "      <td>lie</td>\n",
       "      <td>trial_lie_039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trial_truth_004_009.mp4</td>\n",
       "      <td>./data/Video_chunks/Video_chunks\\trial_truth_0...</td>\n",
       "      <td>4.21</td>\n",
       "      <td>29.97003</td>\n",
       "      <td>126.173826</td>\n",
       "      <td>truth</td>\n",
       "      <td>trial_truth_004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trial_lie_052_002.mp4</td>\n",
       "      <td>./data/Video_chunks/Video_chunks\\trial_lie_052...</td>\n",
       "      <td>3.90</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>lie</td>\n",
       "      <td>trial_lie_052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trial_truth_039_003.mp4</td>\n",
       "      <td>./data/Video_chunks/Video_chunks\\trial_truth_0...</td>\n",
       "      <td>3.96</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>truth</td>\n",
       "      <td>trial_truth_039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trial_truth_045_005.mp4</td>\n",
       "      <td>./data/Video_chunks/Video_chunks\\trial_truth_0...</td>\n",
       "      <td>4.51</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>truth</td>\n",
       "      <td>trial_truth_045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>trial_truth_005_002.mp4</td>\n",
       "      <td>./data/Video_chunks/Video_chunks\\trial_truth_0...</td>\n",
       "      <td>3.90</td>\n",
       "      <td>29.97003</td>\n",
       "      <td>116.883117</td>\n",
       "      <td>truth</td>\n",
       "      <td>trial_truth_005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>trial_truth_015_004.mp4</td>\n",
       "      <td>./data/Video_chunks/Video_chunks\\trial_truth_0...</td>\n",
       "      <td>3.90</td>\n",
       "      <td>29.97003</td>\n",
       "      <td>116.883117</td>\n",
       "      <td>truth</td>\n",
       "      <td>trial_truth_015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>trial_truth_018_001.mp4</td>\n",
       "      <td>./data/Video_chunks/Video_chunks\\trial_truth_0...</td>\n",
       "      <td>3.08</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>truth</td>\n",
       "      <td>trial_truth_018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>trial_truth_042_001.mp4</td>\n",
       "      <td>./data/Video_chunks/Video_chunks\\trial_truth_0...</td>\n",
       "      <td>3.60</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>truth</td>\n",
       "      <td>trial_truth_042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>trial_truth_022_006.mp4</td>\n",
       "      <td>./data/Video_chunks/Video_chunks\\trial_truth_0...</td>\n",
       "      <td>4.21</td>\n",
       "      <td>29.97003</td>\n",
       "      <td>126.173826</td>\n",
       "      <td>truth</td>\n",
       "      <td>trial_truth_022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  video_name  \\\n",
       "0      trial_lie_039_006.mp4   \n",
       "1    trial_truth_004_009.mp4   \n",
       "2      trial_lie_052_002.mp4   \n",
       "3    trial_truth_039_003.mp4   \n",
       "4    trial_truth_045_005.mp4   \n",
       "..                       ...   \n",
       "515  trial_truth_005_002.mp4   \n",
       "516  trial_truth_015_004.mp4   \n",
       "517  trial_truth_018_001.mp4   \n",
       "518  trial_truth_042_001.mp4   \n",
       "519  trial_truth_022_006.mp4   \n",
       "\n",
       "                                            video_path  duration_in_seconds  \\\n",
       "0    ./data/Video_chunks/Video_chunks\\trial_lie_039...                 4.02   \n",
       "1    ./data/Video_chunks/Video_chunks\\trial_truth_0...                 4.21   \n",
       "2    ./data/Video_chunks/Video_chunks\\trial_lie_052...                 3.90   \n",
       "3    ./data/Video_chunks/Video_chunks\\trial_truth_0...                 3.96   \n",
       "4    ./data/Video_chunks/Video_chunks\\trial_truth_0...                 4.51   \n",
       "..                                                 ...                  ...   \n",
       "515  ./data/Video_chunks/Video_chunks\\trial_truth_0...                 3.90   \n",
       "516  ./data/Video_chunks/Video_chunks\\trial_truth_0...                 3.90   \n",
       "517  ./data/Video_chunks/Video_chunks\\trial_truth_0...                 3.08   \n",
       "518  ./data/Video_chunks/Video_chunks\\trial_truth_0...                 3.60   \n",
       "519  ./data/Video_chunks/Video_chunks\\trial_truth_0...                 4.21   \n",
       "\n",
       "          FPS  total_frame_count  label  video_root_name  \n",
       "0    27.00000         108.540000    lie    trial_lie_039  \n",
       "1    29.97003         126.173826  truth  trial_truth_004  \n",
       "2    30.00000         117.000000    lie    trial_lie_052  \n",
       "3    25.00000          99.000000  truth  trial_truth_039  \n",
       "4    10.00000          45.100000  truth  trial_truth_045  \n",
       "..        ...                ...    ...              ...  \n",
       "515  29.97003         116.883117  truth  trial_truth_005  \n",
       "516  29.97003         116.883117  truth  trial_truth_015  \n",
       "517  25.00000          77.000000  truth  trial_truth_018  \n",
       "518  10.00000          36.000000  truth  trial_truth_042  \n",
       "519  29.97003         126.173826  truth  trial_truth_022  \n",
       "\n",
       "[520 rows x 7 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = \"/Users/shreya/606 Capstone/train_DARE_3.csv\"\n",
    "train_file = pd.read_csv(train_path)\n",
    "train_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc135769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shreya/606 Capstone/OpenFace 2/trial_lie_008_001.csv\n",
      "['/Users/shreya/606 Capstone/OpenFace 2/trial_lie_030_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_011_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_006_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_059_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_031_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_024_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_015_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_048_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_011_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_004_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_013_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_053_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_050_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_022_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_057_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_053_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_040_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_025_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_029_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_012_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_043_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_053_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_011_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_013_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_026_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_021_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_046_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_047_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_011_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_046_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_009_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_009_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_059_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_023_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_010_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_001_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_017_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_042_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_060_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_008_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_004_018.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_030_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_059_007.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_004_016.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_001_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_022_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_060_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_005_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_047_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_013_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_022_009.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_060_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_059_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_041_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_040_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_031_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_033_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_050_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_039_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_015_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_004_015.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_005_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_052_011.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_015_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_033_008.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_005_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_035_007.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_053_008.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_052_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_004_019.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_057_008.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_002_007.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_008_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_022_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_010_010.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_016_007.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_037_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_029_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_020_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_010_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_025_007.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_026_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_004_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_017_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_049_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_019_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_010_008.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_023_010.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_009_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_058_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_042_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_036_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_060_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_055_007.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_054_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_055_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_031_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_010_009.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_002_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_052_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_048_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_052_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_009_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_007_012.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_047_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_006_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_023_008.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_002_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_041_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_030_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_010_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_017_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_061_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_017_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_007_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_002_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_004_017.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_007_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_019_008.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_059_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_010_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_003_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_046_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_022_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_007_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_044_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_056_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_023_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_048_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_055_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_006_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_061_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_049_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_047_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_012_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_006_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_010_011.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_021_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_048_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_025_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_007_007.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_040_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_026_007.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_015_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_046_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_038_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_011_009.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_053_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_027_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_041_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_042_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_014_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_006_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_019_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_025_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_035_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_008_001.csv']\n"
     ]
    }
   ],
   "source": [
    "#create an array of the training file names with path\n",
    "# Create an empty list to store the file names with path\n",
    "train_file_names_1 = []\n",
    "\n",
    "# Define the path to the directory containing the training files\n",
    "train_dir_path = \"/Users/shreya/606 Capstone/OpenFace 2/\"\n",
    "\n",
    "# Loop through each file in the directory and append the file name with path to the list\n",
    "for filename in test_file[\"video_name\"]:\n",
    "    path = filepath + filename + \".csv\"\n",
    "    if(os.path.exists(path)):\n",
    "        train_file_names_1.append(path)\n",
    "print(path)\n",
    "# Print the list of file names with path\n",
    "print(train_file_names_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3beb5097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an array of the testing file names with path\n",
    "test_file_contents = []\n",
    "filepath = \"/Users/shreya/606 Capstone/OpenFace 2/\"\n",
    "for filename in test_file[\"video_name\"]:\n",
    "    path = filepath + filename + \".csv\"\n",
    "    if(os.path.exists(path)):\n",
    "        test_file_contents.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1add96ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/shreya/606 Capstone/OpenFace 2/trial_lie_030_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_011_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_006_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_059_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_031_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_024_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_015_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_048_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_011_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_004_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_013_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_053_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_050_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_022_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_057_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_053_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_040_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_025_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_029_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_012_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_043_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_053_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_011_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_013_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_026_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_021_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_046_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_047_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_011_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_046_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_009_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_009_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_059_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_023_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_010_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_001_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_017_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_042_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_060_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_008_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_004_018.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_030_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_059_007.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_004_016.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_001_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_022_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_060_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_005_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_047_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_013_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_022_009.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_060_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_059_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_041_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_040_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_031_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_033_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_050_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_039_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_015_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_004_015.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_005_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_052_011.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_015_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_033_008.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_005_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_035_007.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_053_008.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_052_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_004_019.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_057_008.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_002_007.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_008_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_022_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_010_010.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_016_007.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_037_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_029_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_020_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_010_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_025_007.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_026_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_004_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_017_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_049_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_019_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_010_008.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_023_010.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_009_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_058_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_042_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_036_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_060_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_055_007.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_054_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_055_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_031_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_010_009.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_002_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_052_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_048_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_052_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_009_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_007_012.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_047_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_006_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_023_008.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_002_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_041_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_030_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_010_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_017_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_061_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_017_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_007_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_002_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_004_017.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_007_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_019_008.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_059_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_010_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_003_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_046_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_022_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_007_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_044_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_056_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_023_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_048_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_055_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_006_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_061_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_049_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_047_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_012_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_006_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_010_011.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_021_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_048_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_025_004.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_007_007.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_040_002.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_026_007.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_015_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_046_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_038_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_011_009.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_053_003.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_027_005.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_041_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_042_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_014_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_006_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_019_001.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_truth_025_000.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_035_006.csv', '/Users/shreya/606 Capstone/OpenFace 2/trial_lie_008_001.csv']\n"
     ]
    }
   ],
   "source": [
    "print(test_file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eed42887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate the files using a Fex dataframe\n",
    "from feat.utils.io import read_feat\n",
    "\n",
    "fex_train = pd.concat(map(lambda excel: read_feat(excel), train_file_names_1))\n",
    "fex_test = pd.concat(map(lambda excel: read_feat(excel), test_file_contents))\n",
    "\n",
    "#drop null values\n",
    "fex_train = fex_train.dropna()\n",
    "fex_test = fex_test.dropna()\n",
    "\n",
    "#add label column\n",
    "fex_train.loc[fex_train['input'].str.contains('lie'), 'Label'] = 1\n",
    "fex_train.loc[fex_train['input'].str.contains('truth'), 'Label'] = 0\n",
    "fex_train['Label'] = fex_train['Label'].astype(int)\n",
    "\n",
    "fex_test.loc[fex_test['input'].str.contains('lie'), 'Label'] = 1\n",
    "fex_test.loc[fex_test['input'].str.contains('truth'), 'Label'] = 0\n",
    "fex_test['Label'] = fex_test['Label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d6b09b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = fex_train.loc[:, ['AU01','AU02','AU04','AU05','AU06','AU07','AU09','AU10','AU11','AU12','AU14','AU15','AU17','AU20','AU23','AU24','AU25','AU26','AU28','AU43','anger','disgust','fear','happiness','sadness','surprise','neutral']]\n",
    "y_train = fex_train[\"Label\"]\n",
    "X_test = fex_test.loc[:, ['AU01','AU02','AU04','AU05','AU06','AU07','AU09','AU10','AU11','AU12','AU14','AU15','AU17','AU20','AU23','AU24','AU25','AU26','AU28','AU43','anger','disgust','fear','happiness','sadness','surprise','neutral']]\n",
    "y_test = fex_test[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d1d44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = SVC(kernel='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cebed7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a9c9dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ababa1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6843076639136253\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "762e79b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4563,  3981],\n",
       "       [ 2861, 10268]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11afe4f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot(colorbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55c1cc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7297297297297297\n",
      "Recall: 0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "#precision and recall factor\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b652b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100],\n",
       "                         &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;, 0.1, 1, 10],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100],\n",
       "                         &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;, 0.1, 1, 10],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100],\n",
       "                         'gamma': ['scale', 'auto', 0.1, 1, 10],\n",
       "                         'kernel': ['linear', 'rbf', 'sigmoid']})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameter grid to search over\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100], \n",
    "    'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Create SVM estimator object\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "#print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "571d7b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (21673, 27)\n",
      "y_train shape: (21673,)\n",
      "X_test shape: (21673, 27)\n",
      "y_test shape: (21673,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc754c73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c319683a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999953859641028\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SVM with the chosen hyperparameters\n",
    "svm_hyp_ind=SVC(C=10, gamma=10, kernel='rbf')\n",
    "\n",
    "# Train the SVM on the training data\n",
    "svm_hyp_ind.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the SVM on the testing data\n",
    "score = svm_hyp_ind.score(X_test, y_test)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "92fe163e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7421762651509963\n",
      "Recall: 0.8255007997562648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "\n",
    "# Print precision and recall\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f09a79",
   "metadata": {},
   "source": [
    "### MediaPipe Video Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09a762b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.53449488,  0.46958116, -0.01250319],\n",
       "        [ 0.5236764 ,  0.43811584, -0.02371868],\n",
       "        [ 0.52896953,  0.44605669, -0.01239367],\n",
       "        ...,\n",
       "        [ 0.55799693,  0.35807166, -0.00662516],\n",
       "        [ 0.55452758,  0.36754647, -0.00662516],\n",
       "        [ 0.56025314,  0.37302455, -0.00662516]],\n",
       "\n",
       "       [[ 0.5382098 ,  0.46859151, -0.01248229],\n",
       "        [ 0.52741903,  0.43781245, -0.02392559],\n",
       "        [ 0.53246522,  0.44553134, -0.01248778],\n",
       "        ...,\n",
       "        [ 0.55653548,  0.35851726, -0.00577466],\n",
       "        [ 0.55382174,  0.36763915, -0.00577466],\n",
       "        [ 0.55947435,  0.37304541, -0.00577466]],\n",
       "\n",
       "       [[ 0.53932625,  0.46871126, -0.01289308],\n",
       "        [ 0.52956551,  0.43761429, -0.02445912],\n",
       "        [ 0.53441334,  0.44528556, -0.01277393],\n",
       "        ...,\n",
       "        [ 0.56115246,  0.35567722, -0.00518405],\n",
       "        [ 0.55829924,  0.36458385, -0.00518405],\n",
       "        [ 0.56396765,  0.369726  , -0.00518405]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/shreya/606 Capstone/mediaPipe_keypoints_data_UPD 2/trial_lie_001_000_MP_coord.npy\" \n",
    "data = np.load(path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e71e3f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an array of the training file names with path\n",
    "train_file_names = pd.DataFrame()\n",
    "filepath = \"\"\n",
    "for filename in train_file[\"video_name\"]:\n",
    "    path = filepath + filename + \"_MP_coord.npy\"\n",
    "    if(os.path.exists(path)):\n",
    "        arr = np.load(path)\n",
    "        trun_arr = arr[:,[468, 473, 282, 52, 4, 0, 16, 40, 90, 270, 320, 199],:]\n",
    "        arr_2d = trun_arr.reshape((-1, trun_arr.shape[-1]))\n",
    "        df = pd.DataFrame(arr_2d)\n",
    "        #np.mean(arr, axis=0)\n",
    "        if(\"lie\" in filename):\n",
    "            df['Label'] = 1\n",
    "        elif(\"truth\" in filename):\n",
    "            df['Label'] = 0\n",
    "        train_file_names = train_file_names.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "44cb97ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(train_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c6f88042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.53449488,  0.46958116, -0.01250319],\n",
       "        [ 0.5236764 ,  0.43811584, -0.02371868],\n",
       "        [ 0.52896953,  0.44605669, -0.01239367],\n",
       "        ...,\n",
       "        [ 0.55799693,  0.35807166, -0.00662516],\n",
       "        [ 0.55452758,  0.36754647, -0.00662516],\n",
       "        [ 0.56025314,  0.37302455, -0.00662516]],\n",
       "\n",
       "       [[ 0.5382098 ,  0.46859151, -0.01248229],\n",
       "        [ 0.52741903,  0.43781245, -0.02392559],\n",
       "        [ 0.53246522,  0.44553134, -0.01248778],\n",
       "        ...,\n",
       "        [ 0.55653548,  0.35851726, -0.00577466],\n",
       "        [ 0.55382174,  0.36763915, -0.00577466],\n",
       "        [ 0.55947435,  0.37304541, -0.00577466]],\n",
       "\n",
       "       [[ 0.53932625,  0.46871126, -0.01289308],\n",
       "        [ 0.52956551,  0.43761429, -0.02445912],\n",
       "        [ 0.53441334,  0.44528556, -0.01277393],\n",
       "        ...,\n",
       "        [ 0.56115246,  0.35567722, -0.00518405],\n",
       "        [ 0.55829924,  0.36458385, -0.00518405],\n",
       "        [ 0.56396765,  0.369726  , -0.00518405]]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/shreya/606 Capstone/mediaPipe_keypoints_data_UPD 2/trial_lie_001_000_MP_coord.npy\" \n",
    "data = np.load(path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d8a3e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an array of the training file names with path\n",
    "train_file_names_2 = pd.DataFrame()\n",
    "filepath = \"/Users/shreya/606 Capstone/mediaPipe_keypoints_data_UPD 2/\"\n",
    "for filename in train_file[\"video_name\"]:\n",
    "    path = filepath + filename + \"_MP_coord.npy\"\n",
    "    if(os.path.exists(path)):\n",
    "        arr = np.load(path)\n",
    "        trun_arr = arr[:,[468, 473, 282, 52, 4, 0, 16, 40, 90, 270, 320, 199],:]\n",
    "        arr_2d = trun_arr.reshape((-1, trun_arr.shape[-1]))\n",
    "        df = pd.DataFrame(arr_2d)\n",
    "        #np.mean(arr, axis=0)\n",
    "        if(\"lie\" in filename):\n",
    "            df['Label'] = 1\n",
    "        elif(\"truth\" in filename):\n",
    "            df['Label'] = 0\n",
    "        train_file_names_2 = train_file_names_2.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "27c6684a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(train_file_names_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e734d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an array of the testing file names with path\n",
    "test_file_names = pd.DataFrame()\n",
    "filepath = \"/Users/shreya/606 Capstone/mediaPipe_keypoints_data_UPD 2/\"\n",
    "for filename in test_file[\"video_name\"]:\n",
    "    path = filepath + filename + \"_MP_coord.npy\"\n",
    "    if(os.path.exists(path)):\n",
    "        arr = np.load(path)\n",
    "        trun_arr = arr[:,[468, 473, 282, 52, 4, 0, 16, 40, 90, 270, 320, 199],:]\n",
    "        arr_2d = trun_arr.reshape((-1, trun_arr.shape[-1]))\n",
    "        df = pd.DataFrame(arr_2d)\n",
    "        if(\"lie\" in filename):\n",
    "            df['Label'] = 1\n",
    "        elif(\"truth\" in filename):\n",
    "            df['Label'] = 0\n",
    "        test_file_names = test_file_names.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f4922581",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2  Label\n",
      "0     0.475568  0.352382  0.012695      1\n",
      "1     0.556791  0.331939  0.014174      1\n",
      "2     0.571536  0.276236  0.005984      1\n",
      "3     0.463973  0.303511  0.004575      1\n",
      "4     0.527201  0.420926 -0.044333      1\n",
      "...        ...       ...       ...    ...\n",
      "1111  0.481552  0.431764 -0.013180      1\n",
      "1112  0.481901  0.437959 -0.014088      1\n",
      "1113  0.511643  0.431834 -0.006047      1\n",
      "1114  0.510911  0.437788 -0.008146      1\n",
      "1115  0.498713  0.473030 -0.015571      1\n",
      "\n",
      "[203556 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_file_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_file_names.loc[:, [0,1,2]]\n",
    "X_test = test_file_names.loc[:, [0,1,2]]\n",
    "y_train = train_file_names[\"Label\"]\n",
    "y_test = test_file_names[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbd610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = SVC(kernel='rbf', C=0.1, gamma=0.1)\n",
    "\n",
    "scores = cross_val_score(svm_classifier, X_train, y_train, cv=5)\n",
    "\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Mean score:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f6acefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(kernel = 'rbf', C = 0.1, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Mean score:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588cd43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on the test data\n",
    "# y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131572e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d53cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision and recall factor\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fdd6e3",
   "metadata": {},
   "source": [
    "### MEDIAPIPE AUDIO FILES PREDICTION - MFCC FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78d1f682",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d6cbcc13ce96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_file_names_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/shreya/606 Capstone/audio_features/MFCC_audio_features\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"video_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_MFCC.npy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_file' is not defined"
     ]
    }
   ],
   "source": [
    "#create an array of the training file names with path\n",
    "train_file_names_audio = pd.DataFrame()\n",
    "filepath = \"/Users/shreya/606 Capstone/audio_features/MFCC_audio_features\"\n",
    "for filename in train_file[\"video_name\"]:\n",
    "    path = filepath + filename + \"_MFCC.npy\"\n",
    "    if(os.path.exists(path)):\n",
    "        arr = np.load(path)\n",
    "        trun_arr = arr[:,[468, 473, 282, 52, 4, 0, 16, 40, 90, 270, 320, 199],:]\n",
    "        arr_2d = trun_arr.reshape((-1, trun_arr.shape[-1]))\n",
    "        df = pd.DataFrame(arr_2d)\n",
    "        #np.mean(arr, axis=0)\n",
    "        if(\"lie\" in filename):\n",
    "            df['Label'] = 1\n",
    "        elif(\"truth\" in filename):\n",
    "            df['Label'] = 0\n",
    "        train_file_names_audio = train_file_names_audio.append(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b48ee4",
   "metadata": {},
   "source": [
    "This code reads in the data from the CSV files, extracts the desired columns from each dataframe, concatenates all the dataframes into a single dataframe, splits the data into training and testing sets using the train_test_split function from scikit-learn, fits an SVM model to the training data using scikit-learn's SVC class, and evaluates the accuracy of the model on the testing data using the score method of the SVC object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "03a5a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = \"/Users/shreya/606 Capstone/mediaPipe_keypoints_data_UPD\"\n",
    "# file_list = os.listdir(folder_path)\n",
    "\n",
    "# dataframe_list_1 = []\n",
    "# for file_name in train_file_names:\n",
    "#     if file_name.endswith('.csv'):\n",
    "#         train_file_names = os.path.join(folder_path, file_name)\n",
    "#         dataframe = pd.read_csv(file_path)\n",
    "\n",
    "#         if (\"lie\" in filename):\n",
    "#             df['label'] = 1\n",
    "#         elif (\"truth\" in filename)\n",
    "#             df['label'] = 0\n",
    "#         # Extract the desired columns from the dataframe\n",
    "#         alt_df = dataframe.iloc[:, [468, 473, 282, 5, 4, 0, 16, 40, 90, 270, 320, 199]]\n",
    "        \n",
    "\n",
    "#         # Append the modified dataframe to the list\n",
    "#         dataframe_list_1.append(alt_df)\n",
    "\n",
    "# # print(dataframe_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d2e4bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate all dataframes into a single dataframe\n",
    "# df = pd.concat(dataframe_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1f6f1b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a1a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit an SVM model to the training data\n",
    "# clf = SVC(kernel='rbf')\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b61149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# clf = SVC(kernel='poly')\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf36df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the accuracy of the model on the testing data\n",
    "# accuracy = clf.score(X_test, y_test)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5fbdb1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe 0: (116, 12)\n",
      "Shape of dataframe 1: (125, 12)\n",
      "Shape of dataframe 2: (116, 12)\n",
      "Shape of dataframe 3: (116, 12)\n",
      "Shape of dataframe 4: (125, 12)\n",
      "Shape of dataframe 5: (116, 12)\n",
      "Shape of dataframe 6: (116, 12)\n",
      "Shape of dataframe 7: (116, 12)\n",
      "Shape of dataframe 8: (125, 12)\n",
      "Shape of dataframe 9: (116, 12)\n",
      "Shape of dataframe 10: (116, 12)\n",
      "Shape of dataframe 11: (98, 12)\n",
      "Shape of dataframe 12: (71, 12)\n",
      "Shape of dataframe 13: (116, 12)\n",
      "Shape of dataframe 14: (116, 12)\n",
      "Shape of dataframe 15: (125, 12)\n",
      "Shape of dataframe 16: (116, 12)\n",
      "Shape of dataframe 17: (116, 12)\n",
      "Shape of dataframe 18: (116, 12)\n",
      "Shape of dataframe 19: (125, 12)\n",
      "Shape of dataframe 20: (44, 12)\n",
      "Shape of dataframe 21: (116, 12)\n",
      "Shape of dataframe 22: (116, 12)\n",
      "Shape of dataframe 23: (116, 12)\n",
      "Shape of dataframe 24: (125, 12)\n",
      "Shape of dataframe 25: (105, 12)\n",
      "Shape of dataframe 26: (116, 12)\n",
      "Shape of dataframe 27: (116, 12)\n",
      "Shape of dataframe 28: (116, 12)\n",
      "Shape of dataframe 29: (0, 12)\n",
      "Shape of dataframe 30: (54, 12)\n",
      "Shape of dataframe 31: (116, 12)\n",
      "Shape of dataframe 32: (115, 12)\n",
      "Shape of dataframe 33: (74, 12)\n",
      "Shape of dataframe 34: (44, 12)\n",
      "Shape of dataframe 35: (116, 12)\n",
      "Shape of dataframe 36: (35, 12)\n",
      "Shape of dataframe 37: (125, 12)\n",
      "Shape of dataframe 38: (125, 12)\n",
      "Shape of dataframe 39: (116, 12)\n",
      "Shape of dataframe 40: (125, 12)\n",
      "Shape of dataframe 41: (54, 12)\n",
      "Shape of dataframe 42: (116, 12)\n",
      "Shape of dataframe 43: (116, 12)\n",
      "Shape of dataframe 44: (44, 12)\n",
      "Shape of dataframe 45: (44, 12)\n",
      "Shape of dataframe 46: (125, 12)\n",
      "Shape of dataframe 47: (98, 12)\n",
      "Shape of dataframe 48: (125, 12)\n",
      "Shape of dataframe 49: (116, 12)\n",
      "Shape of dataframe 50: (116, 12)\n",
      "Shape of dataframe 51: (35, 12)\n",
      "Shape of dataframe 52: (125, 12)\n",
      "Shape of dataframe 53: (44, 12)\n",
      "Shape of dataframe 54: (115, 12)\n",
      "Shape of dataframe 55: (116, 12)\n",
      "Shape of dataframe 56: (125, 12)\n",
      "Shape of dataframe 57: (125, 12)\n",
      "Shape of dataframe 58: (107, 12)\n",
      "Shape of dataframe 59: (98, 12)\n",
      "Shape of dataframe 60: (125, 12)\n",
      "Shape of dataframe 61: (116, 12)\n",
      "Shape of dataframe 62: (125, 12)\n",
      "Shape of dataframe 63: (125, 12)\n",
      "Shape of dataframe 64: (35, 12)\n",
      "Shape of dataframe 65: (116, 12)\n",
      "Shape of dataframe 66: (107, 12)\n",
      "Shape of dataframe 67: (116, 12)\n",
      "Shape of dataframe 68: (116, 12)\n",
      "Shape of dataframe 69: (35, 12)\n",
      "Shape of dataframe 70: (125, 12)\n",
      "Shape of dataframe 71: (107, 12)\n",
      "Shape of dataframe 72: (116, 12)\n",
      "Shape of dataframe 73: (125, 12)\n",
      "Shape of dataframe 74: (125, 12)\n",
      "Shape of dataframe 75: (116, 12)\n",
      "Shape of dataframe 76: (84, 12)\n",
      "Shape of dataframe 77: (115, 12)\n",
      "Shape of dataframe 78: (116, 12)\n",
      "Shape of dataframe 79: (120, 12)\n",
      "Shape of dataframe 80: (107, 12)\n",
      "Shape of dataframe 81: (116, 12)\n",
      "Shape of dataframe 82: (125, 12)\n",
      "Shape of dataframe 83: (125, 12)\n",
      "Shape of dataframe 84: (116, 12)\n",
      "Shape of dataframe 85: (115, 12)\n",
      "Shape of dataframe 86: (116, 12)\n",
      "Shape of dataframe 87: (116, 12)\n",
      "Shape of dataframe 88: (116, 12)\n",
      "Shape of dataframe 89: (107, 12)\n",
      "Shape of dataframe 90: (116, 12)\n",
      "Shape of dataframe 91: (115, 12)\n",
      "Shape of dataframe 92: (44, 12)\n",
      "Shape of dataframe 93: (107, 12)\n",
      "Shape of dataframe 94: (125, 12)\n",
      "Shape of dataframe 95: (125, 12)\n",
      "Shape of dataframe 96: (125, 12)\n",
      "Shape of dataframe 97: (23, 12)\n",
      "Shape of dataframe 98: (37, 12)\n",
      "Shape of dataframe 99: (116, 12)\n",
      "Shape of dataframe 100: (116, 12)\n",
      "Shape of dataframe 101: (125, 12)\n",
      "Shape of dataframe 102: (107, 12)\n",
      "Shape of dataframe 103: (75, 12)\n",
      "Shape of dataframe 104: (35, 12)\n",
      "Shape of dataframe 105: (125, 12)\n",
      "Shape of dataframe 106: (35, 12)\n",
      "Shape of dataframe 107: (116, 12)\n",
      "Shape of dataframe 108: (125, 12)\n",
      "Shape of dataframe 109: (107, 12)\n",
      "Shape of dataframe 110: (125, 12)\n",
      "Shape of dataframe 111: (15, 12)\n",
      "Shape of dataframe 112: (125, 12)\n",
      "Shape of dataframe 113: (2, 12)\n",
      "Shape of dataframe 114: (125, 12)\n",
      "Shape of dataframe 115: (41, 12)\n",
      "Shape of dataframe 116: (125, 12)\n",
      "Shape of dataframe 117: (116, 12)\n",
      "Shape of dataframe 118: (44, 12)\n",
      "Shape of dataframe 119: (115, 12)\n",
      "Shape of dataframe 120: (35, 12)\n",
      "Shape of dataframe 121: (116, 12)\n",
      "Shape of dataframe 122: (116, 12)\n",
      "Shape of dataframe 123: (116, 12)\n",
      "Shape of dataframe 124: (44, 12)\n",
      "Shape of dataframe 125: (125, 12)\n",
      "Shape of dataframe 126: (125, 12)\n",
      "Shape of dataframe 127: (125, 12)\n",
      "Shape of dataframe 128: (81, 12)\n",
      "Shape of dataframe 129: (125, 12)\n",
      "Shape of dataframe 130: (125, 12)\n",
      "Shape of dataframe 131: (125, 12)\n",
      "Shape of dataframe 132: (116, 12)\n",
      "Shape of dataframe 133: (125, 12)\n",
      "Shape of dataframe 134: (125, 12)\n",
      "Shape of dataframe 135: (116, 12)\n",
      "Shape of dataframe 136: (92, 12)\n",
      "Shape of dataframe 137: (125, 12)\n",
      "Shape of dataframe 138: (116, 12)\n",
      "Shape of dataframe 139: (107, 12)\n",
      "Shape of dataframe 140: (22, 12)\n",
      "Shape of dataframe 141: (125, 12)\n",
      "Shape of dataframe 142: (125, 12)\n",
      "Shape of dataframe 143: (125, 12)\n",
      "Shape of dataframe 144: (116, 12)\n",
      "Shape of dataframe 145: (116, 12)\n",
      "Shape of dataframe 146: (125, 12)\n",
      "Shape of dataframe 147: (107, 12)\n",
      "Shape of dataframe 148: (35, 12)\n",
      "Shape of dataframe 149: (116, 12)\n",
      "Shape of dataframe 150: (87, 12)\n",
      "Shape of dataframe 151: (98, 12)\n",
      "Shape of dataframe 152: (116, 12)\n",
      "Shape of dataframe 153: (125, 12)\n",
      "Shape of dataframe 154: (116, 12)\n",
      "Shape of dataframe 155: (125, 12)\n",
      "Shape of dataframe 156: (125, 12)\n",
      "Shape of dataframe 157: (116, 12)\n",
      "Shape of dataframe 158: (44, 12)\n",
      "Shape of dataframe 159: (116, 12)\n",
      "Shape of dataframe 160: (116, 12)\n",
      "Shape of dataframe 161: (116, 12)\n",
      "Shape of dataframe 162: (89, 12)\n",
      "Shape of dataframe 163: (116, 12)\n",
      "Shape of dataframe 164: (116, 12)\n",
      "Shape of dataframe 165: (44, 12)\n",
      "Shape of dataframe 166: (125, 12)\n",
      "Shape of dataframe 167: (116, 12)\n",
      "Shape of dataframe 168: (115, 12)\n",
      "Shape of dataframe 169: (107, 12)\n",
      "Shape of dataframe 170: (72, 12)\n",
      "Shape of dataframe 171: (56, 12)\n",
      "Shape of dataframe 172: (125, 12)\n",
      "Shape of dataframe 173: (125, 12)\n",
      "Shape of dataframe 174: (116, 12)\n",
      "Shape of dataframe 175: (125, 12)\n",
      "Shape of dataframe 176: (47, 12)\n",
      "Shape of dataframe 177: (116, 12)\n",
      "Shape of dataframe 178: (116, 12)\n",
      "Shape of dataframe 179: (44, 12)\n",
      "Shape of dataframe 180: (116, 12)\n",
      "Shape of dataframe 181: (125, 12)\n",
      "Shape of dataframe 182: (125, 12)\n",
      "Shape of dataframe 183: (35, 12)\n",
      "Shape of dataframe 184: (116, 12)\n",
      "Shape of dataframe 185: (125, 12)\n",
      "Shape of dataframe 186: (35, 12)\n",
      "Shape of dataframe 187: (107, 12)\n",
      "Shape of dataframe 188: (125, 12)\n",
      "Shape of dataframe 189: (116, 12)\n",
      "Shape of dataframe 190: (44, 12)\n",
      "Shape of dataframe 191: (98, 12)\n",
      "Shape of dataframe 192: (98, 12)\n",
      "Shape of dataframe 193: (98, 12)\n",
      "Shape of dataframe 194: (116, 12)\n",
      "Shape of dataframe 195: (54, 12)\n",
      "Shape of dataframe 196: (125, 12)\n",
      "Shape of dataframe 197: (125, 12)\n",
      "Shape of dataframe 198: (116, 12)\n",
      "Shape of dataframe 199: (125, 12)\n",
      "Shape of dataframe 200: (35, 12)\n",
      "Shape of dataframe 201: (125, 12)\n",
      "Shape of dataframe 202: (35, 12)\n",
      "Shape of dataframe 203: (24, 12)\n",
      "Shape of dataframe 204: (116, 12)\n",
      "Shape of dataframe 205: (116, 12)\n",
      "Shape of dataframe 206: (116, 12)\n",
      "Shape of dataframe 207: (116, 12)\n",
      "Shape of dataframe 208: (27, 12)\n",
      "Shape of dataframe 209: (125, 12)\n",
      "Shape of dataframe 210: (35, 12)\n",
      "Shape of dataframe 211: (116, 12)\n",
      "Shape of dataframe 212: (125, 12)\n",
      "Shape of dataframe 213: (116, 12)\n",
      "Shape of dataframe 214: (125, 12)\n",
      "Shape of dataframe 215: (116, 12)\n",
      "Shape of dataframe 216: (116, 12)\n",
      "Shape of dataframe 217: (98, 12)\n",
      "Shape of dataframe 218: (116, 12)\n",
      "Shape of dataframe 219: (116, 12)\n",
      "Shape of dataframe 220: (116, 12)\n",
      "Shape of dataframe 221: (125, 12)\n",
      "Shape of dataframe 222: (116, 12)\n",
      "Shape of dataframe 223: (30, 12)\n",
      "Shape of dataframe 224: (71, 12)\n",
      "Shape of dataframe 225: (35, 12)\n",
      "Shape of dataframe 226: (116, 12)\n",
      "Shape of dataframe 227: (116, 12)\n",
      "Shape of dataframe 228: (115, 12)\n",
      "Shape of dataframe 229: (125, 12)\n",
      "Shape of dataframe 230: (116, 12)\n",
      "Shape of dataframe 231: (116, 12)\n",
      "Shape of dataframe 232: (44, 12)\n",
      "Shape of dataframe 233: (35, 12)\n",
      "Shape of dataframe 234: (125, 12)\n",
      "Shape of dataframe 235: (116, 12)\n",
      "Shape of dataframe 236: (116, 12)\n",
      "Shape of dataframe 237: (116, 12)\n",
      "Shape of dataframe 238: (44, 12)\n",
      "Shape of dataframe 239: (35, 12)\n",
      "Shape of dataframe 240: (116, 12)\n",
      "Shape of dataframe 241: (116, 12)\n",
      "Shape of dataframe 242: (29, 12)\n",
      "Shape of dataframe 243: (125, 12)\n",
      "Shape of dataframe 244: (107, 12)\n",
      "Shape of dataframe 245: (116, 12)\n",
      "Shape of dataframe 246: (125, 12)\n",
      "Shape of dataframe 247: (125, 12)\n",
      "Shape of dataframe 248: (116, 12)\n",
      "Shape of dataframe 249: (125, 12)\n",
      "Shape of dataframe 250: (125, 12)\n",
      "Shape of dataframe 251: (125, 12)\n",
      "Shape of dataframe 252: (98, 12)\n",
      "Shape of dataframe 253: (116, 12)\n",
      "Shape of dataframe 254: (116, 12)\n",
      "Shape of dataframe 255: (84, 12)\n",
      "Shape of dataframe 256: (116, 12)\n",
      "Shape of dataframe 257: (125, 12)\n",
      "Shape of dataframe 258: (125, 12)\n",
      "Shape of dataframe 259: (98, 12)\n",
      "Shape of dataframe 260: (107, 12)\n",
      "Shape of dataframe 261: (115, 12)\n",
      "Shape of dataframe 262: (105, 12)\n",
      "Shape of dataframe 263: (125, 12)\n",
      "Shape of dataframe 264: (116, 12)\n",
      "Shape of dataframe 265: (107, 12)\n",
      "Shape of dataframe 266: (60, 12)\n",
      "Shape of dataframe 267: (125, 12)\n",
      "Shape of dataframe 268: (35, 12)\n",
      "Shape of dataframe 269: (64, 12)\n",
      "Shape of dataframe 270: (15, 12)\n",
      "Shape of dataframe 271: (98, 12)\n",
      "Shape of dataframe 272: (44, 12)\n",
      "Shape of dataframe 273: (116, 12)\n",
      "Shape of dataframe 274: (116, 12)\n",
      "Shape of dataframe 275: (116, 12)\n",
      "Shape of dataframe 276: (116, 12)\n",
      "Shape of dataframe 277: (116, 12)\n",
      "Shape of dataframe 278: (116, 12)\n",
      "Shape of dataframe 279: (107, 12)\n",
      "Shape of dataframe 280: (116, 12)\n",
      "Shape of dataframe 281: (116, 12)\n",
      "Shape of dataframe 282: (125, 12)\n",
      "Shape of dataframe 283: (116, 12)\n",
      "Shape of dataframe 284: (107, 12)\n",
      "Shape of dataframe 285: (44, 12)\n",
      "Shape of dataframe 286: (0, 12)\n",
      "Shape of dataframe 287: (116, 12)\n",
      "Shape of dataframe 288: (125, 12)\n",
      "Shape of dataframe 289: (116, 12)\n",
      "Shape of dataframe 290: (116, 12)\n",
      "Shape of dataframe 291: (116, 12)\n",
      "Shape of dataframe 292: (116, 12)\n",
      "Shape of dataframe 293: (116, 12)\n",
      "Shape of dataframe 294: (44, 12)\n",
      "Shape of dataframe 295: (116, 12)\n",
      "Shape of dataframe 296: (125, 12)\n",
      "Shape of dataframe 297: (14, 12)\n",
      "Shape of dataframe 298: (125, 12)\n",
      "Shape of dataframe 299: (98, 12)\n",
      "Shape of dataframe 300: (21, 12)\n",
      "Shape of dataframe 301: (115, 12)\n",
      "Shape of dataframe 302: (125, 12)\n",
      "Shape of dataframe 303: (116, 12)\n",
      "Shape of dataframe 304: (62, 12)\n",
      "Shape of dataframe 305: (98, 12)\n",
      "Shape of dataframe 306: (116, 12)\n",
      "Shape of dataframe 307: (80, 12)\n",
      "Shape of dataframe 308: (125, 12)\n",
      "Shape of dataframe 309: (115, 12)\n",
      "Shape of dataframe 310: (116, 12)\n",
      "Shape of dataframe 311: (116, 12)\n",
      "Shape of dataframe 312: (116, 12)\n",
      "Shape of dataframe 313: (98, 12)\n",
      "Shape of dataframe 314: (125, 12)\n",
      "Shape of dataframe 315: (98, 12)\n",
      "Shape of dataframe 316: (125, 12)\n",
      "Shape of dataframe 317: (116, 12)\n",
      "Shape of dataframe 318: (125, 12)\n",
      "Shape of dataframe 319: (116, 12)\n",
      "Shape of dataframe 320: (116, 12)\n",
      "Shape of dataframe 321: (59, 12)\n",
      "Shape of dataframe 322: (107, 12)\n",
      "Shape of dataframe 323: (116, 12)\n",
      "Shape of dataframe 324: (0, 12)\n",
      "Shape of dataframe 325: (19, 12)\n",
      "Shape of dataframe 326: (116, 12)\n",
      "Shape of dataframe 327: (125, 12)\n",
      "Shape of dataframe 328: (125, 12)\n",
      "Shape of dataframe 329: (116, 12)\n",
      "Shape of dataframe 330: (98, 12)\n",
      "Shape of dataframe 331: (116, 12)\n",
      "Shape of dataframe 332: (30, 12)\n",
      "Shape of dataframe 333: (35, 12)\n",
      "Shape of dataframe 334: (125, 12)\n",
      "Shape of dataframe 335: (116, 12)\n",
      "Shape of dataframe 336: (116, 12)\n",
      "Shape of dataframe 337: (125, 12)\n",
      "Shape of dataframe 338: (35, 12)\n",
      "Shape of dataframe 339: (116, 12)\n",
      "Shape of dataframe 340: (35, 12)\n",
      "Shape of dataframe 341: (54, 12)\n",
      "Shape of dataframe 342: (44, 12)\n",
      "Shape of dataframe 343: (35, 12)\n",
      "Shape of dataframe 344: (98, 12)\n",
      "Shape of dataframe 345: (116, 12)\n",
      "Shape of dataframe 346: (35, 12)\n",
      "Shape of dataframe 347: (125, 12)\n",
      "Shape of dataframe 348: (125, 12)\n",
      "Shape of dataframe 349: (116, 12)\n",
      "Shape of dataframe 350: (115, 12)\n",
      "Shape of dataframe 351: (125, 12)\n",
      "Shape of dataframe 352: (116, 12)\n",
      "Shape of dataframe 353: (116, 12)\n",
      "Shape of dataframe 354: (116, 12)\n",
      "Shape of dataframe 355: (80, 12)\n",
      "Shape of dataframe 356: (125, 12)\n",
      "Shape of dataframe 357: (116, 12)\n",
      "Shape of dataframe 358: (107, 12)\n",
      "Shape of dataframe 359: (125, 12)\n",
      "Shape of dataframe 360: (116, 12)\n",
      "Shape of dataframe 361: (98, 12)\n",
      "Shape of dataframe 362: (116, 12)\n",
      "Shape of dataframe 363: (125, 12)\n",
      "Shape of dataframe 364: (125, 12)\n",
      "Shape of dataframe 365: (44, 12)\n",
      "Shape of dataframe 366: (115, 12)\n",
      "Shape of dataframe 367: (115, 12)\n",
      "Shape of dataframe 368: (125, 12)\n",
      "Shape of dataframe 369: (125, 12)\n",
      "Shape of dataframe 370: (125, 12)\n",
      "Shape of dataframe 371: (116, 12)\n",
      "Shape of dataframe 372: (116, 12)\n",
      "Shape of dataframe 373: (125, 12)\n",
      "Shape of dataframe 374: (116, 12)\n",
      "Shape of dataframe 375: (125, 12)\n",
      "Shape of dataframe 376: (116, 12)\n",
      "Shape of dataframe 377: (125, 12)\n",
      "Shape of dataframe 378: (116, 12)\n",
      "Shape of dataframe 379: (116, 12)\n",
      "Shape of dataframe 380: (116, 12)\n",
      "Shape of dataframe 381: (116, 12)\n",
      "Shape of dataframe 382: (98, 12)\n",
      "Shape of dataframe 383: (116, 12)\n",
      "Shape of dataframe 384: (120, 12)\n",
      "Shape of dataframe 385: (116, 12)\n",
      "Shape of dataframe 386: (44, 12)\n",
      "Shape of dataframe 387: (35, 12)\n",
      "Shape of dataframe 388: (80, 12)\n",
      "Shape of dataframe 389: (35, 12)\n",
      "Shape of dataframe 390: (98, 12)\n",
      "Shape of dataframe 391: (115, 12)\n",
      "Shape of dataframe 392: (116, 12)\n",
      "Shape of dataframe 393: (116, 12)\n",
      "Shape of dataframe 394: (125, 12)\n",
      "Shape of dataframe 395: (20, 12)\n",
      "Shape of dataframe 396: (64, 12)\n",
      "Shape of dataframe 397: (125, 12)\n",
      "Shape of dataframe 398: (45, 12)\n",
      "Shape of dataframe 399: (116, 12)\n",
      "Shape of dataframe 400: (116, 12)\n",
      "Shape of dataframe 401: (116, 12)\n",
      "Shape of dataframe 402: (44, 12)\n",
      "Shape of dataframe 403: (88, 12)\n",
      "Shape of dataframe 404: (125, 12)\n",
      "Shape of dataframe 405: (35, 12)\n",
      "Shape of dataframe 406: (35, 12)\n",
      "Shape of dataframe 407: (116, 12)\n",
      "Shape of dataframe 408: (116, 12)\n",
      "Shape of dataframe 409: (74, 12)\n",
      "Shape of dataframe 410: (116, 12)\n",
      "Shape of dataframe 411: (107, 12)\n",
      "Shape of dataframe 412: (44, 12)\n",
      "Shape of dataframe 413: (125, 12)\n",
      "Shape of dataframe 414: (115, 12)\n",
      "Shape of dataframe 415: (116, 12)\n",
      "Shape of dataframe 416: (115, 12)\n",
      "Shape of dataframe 417: (116, 12)\n",
      "Shape of dataframe 418: (35, 12)\n",
      "Shape of dataframe 419: (116, 12)\n",
      "Shape of dataframe 420: (5, 12)\n",
      "Shape of dataframe 421: (35, 12)\n",
      "Shape of dataframe 422: (116, 12)\n",
      "Shape of dataframe 423: (116, 12)\n",
      "Shape of dataframe 424: (125, 12)\n",
      "Shape of dataframe 425: (36, 12)\n",
      "Shape of dataframe 426: (71, 12)\n",
      "Shape of dataframe 427: (125, 12)\n",
      "Shape of dataframe 428: (116, 12)\n",
      "Shape of dataframe 429: (107, 12)\n",
      "Shape of dataframe 430: (107, 12)\n",
      "Shape of dataframe 431: (116, 12)\n",
      "Shape of dataframe 432: (125, 12)\n",
      "Shape of dataframe 433: (125, 12)\n",
      "Shape of dataframe 434: (116, 12)\n",
      "Shape of dataframe 435: (35, 12)\n",
      "Shape of dataframe 436: (79, 12)\n",
      "Shape of dataframe 437: (107, 12)\n",
      "Shape of dataframe 438: (125, 12)\n",
      "Shape of dataframe 439: (116, 12)\n",
      "Shape of dataframe 440: (16, 12)\n",
      "Shape of dataframe 441: (107, 12)\n",
      "Shape of dataframe 442: (125, 12)\n",
      "Shape of dataframe 443: (35, 12)\n",
      "Shape of dataframe 444: (125, 12)\n",
      "Shape of dataframe 445: (125, 12)\n",
      "Shape of dataframe 446: (35, 12)\n",
      "Shape of dataframe 447: (125, 12)\n",
      "Shape of dataframe 448: (125, 12)\n",
      "Shape of dataframe 449: (45, 12)\n",
      "Shape of dataframe 450: (35, 12)\n",
      "Shape of dataframe 451: (125, 12)\n",
      "Shape of dataframe 452: (116, 12)\n",
      "Shape of dataframe 453: (98, 12)\n",
      "Shape of dataframe 454: (125, 12)\n",
      "Shape of dataframe 455: (125, 12)\n",
      "Shape of dataframe 456: (98, 12)\n",
      "Shape of dataframe 457: (32, 12)\n",
      "Shape of dataframe 458: (125, 12)\n",
      "Shape of dataframe 459: (125, 12)\n",
      "Shape of dataframe 460: (35, 12)\n",
      "Shape of dataframe 461: (116, 12)\n",
      "Shape of dataframe 462: (116, 12)\n",
      "Shape of dataframe 463: (90, 12)\n",
      "Shape of dataframe 464: (116, 12)\n",
      "Shape of dataframe 465: (116, 12)\n",
      "Shape of dataframe 466: (125, 12)\n",
      "Shape of dataframe 467: (125, 12)\n",
      "Shape of dataframe 468: (116, 12)\n",
      "Shape of dataframe 469: (116, 12)\n",
      "Shape of dataframe 470: (125, 12)\n",
      "Shape of dataframe 471: (116, 12)\n",
      "Shape of dataframe 472: (125, 12)\n",
      "Shape of dataframe 473: (125, 12)\n",
      "Shape of dataframe 474: (125, 12)\n",
      "Shape of dataframe 475: (57, 12)\n",
      "Shape of dataframe 476: (107, 12)\n",
      "Shape of dataframe 477: (35, 12)\n",
      "Shape of dataframe 478: (98, 12)\n",
      "Shape of dataframe 479: (22, 12)\n",
      "Shape of dataframe 480: (116, 12)\n",
      "Shape of dataframe 481: (48, 12)\n",
      "Shape of dataframe 482: (9, 12)\n",
      "Shape of dataframe 483: (116, 12)\n",
      "Shape of dataframe 484: (10, 12)\n",
      "Shape of dataframe 485: (70, 12)\n",
      "Shape of dataframe 486: (107, 12)\n",
      "Shape of dataframe 487: (125, 12)\n",
      "Shape of dataframe 488: (44, 12)\n",
      "Shape of dataframe 489: (116, 12)\n",
      "Shape of dataframe 490: (125, 12)\n",
      "Shape of dataframe 491: (125, 12)\n",
      "Shape of dataframe 492: (116, 12)\n",
      "Shape of dataframe 493: (116, 12)\n",
      "Shape of dataframe 494: (116, 12)\n",
      "Shape of dataframe 495: (116, 12)\n",
      "Shape of dataframe 496: (116, 12)\n",
      "Shape of dataframe 497: (98, 12)\n",
      "Shape of dataframe 498: (98, 12)\n",
      "Shape of dataframe 499: (107, 12)\n",
      "Shape of dataframe 500: (116, 12)\n",
      "Shape of dataframe 501: (116, 12)\n",
      "Shape of dataframe 502: (125, 12)\n",
      "Shape of dataframe 503: (116, 12)\n",
      "Shape of dataframe 504: (116, 12)\n",
      "Shape of dataframe 505: (44, 12)\n",
      "Shape of dataframe 506: (116, 12)\n",
      "Shape of dataframe 507: (125, 12)\n",
      "Shape of dataframe 508: (116, 12)\n",
      "Shape of dataframe 509: (116, 12)\n",
      "Shape of dataframe 510: (125, 12)\n",
      "Shape of dataframe 511: (125, 12)\n",
      "Shape of dataframe 512: (125, 12)\n",
      "Shape of dataframe 513: (125, 12)\n",
      "Shape of dataframe 514: (101, 12)\n",
      "Shape of dataframe 515: (116, 12)\n",
      "Shape of dataframe 516: (56, 12)\n",
      "Shape of dataframe 517: (116, 12)\n",
      "Shape of dataframe 518: (116, 12)\n",
      "Shape of dataframe 519: (24, 12)\n",
      "Shape of dataframe 520: (116, 12)\n",
      "Shape of dataframe 521: (116, 12)\n",
      "Shape of dataframe 522: (116, 12)\n",
      "Shape of dataframe 523: (44, 12)\n",
      "Shape of dataframe 524: (116, 12)\n",
      "Shape of dataframe 525: (62, 12)\n",
      "Shape of dataframe 526: (116, 12)\n",
      "Shape of dataframe 527: (35, 12)\n",
      "Shape of dataframe 528: (44, 12)\n",
      "Shape of dataframe 529: (125, 12)\n",
      "Shape of dataframe 530: (20, 12)\n",
      "Shape of dataframe 531: (46, 12)\n",
      "Shape of dataframe 532: (116, 12)\n",
      "Shape of dataframe 533: (125, 12)\n",
      "Shape of dataframe 534: (60, 12)\n",
      "Shape of dataframe 535: (107, 12)\n",
      "Shape of dataframe 536: (80, 12)\n",
      "Shape of dataframe 537: (116, 12)\n",
      "Shape of dataframe 538: (116, 12)\n",
      "Shape of dataframe 539: (116, 12)\n",
      "Shape of dataframe 540: (84, 12)\n",
      "Shape of dataframe 541: (71, 12)\n",
      "Shape of dataframe 542: (107, 12)\n",
      "Shape of dataframe 543: (125, 12)\n",
      "Shape of dataframe 544: (116, 12)\n",
      "Shape of dataframe 545: (35, 12)\n",
      "Shape of dataframe 546: (116, 12)\n",
      "Shape of dataframe 547: (125, 12)\n",
      "Shape of dataframe 548: (125, 12)\n",
      "Shape of dataframe 549: (124, 12)\n",
      "Shape of dataframe 550: (107, 12)\n",
      "Shape of dataframe 551: (125, 12)\n",
      "Shape of dataframe 552: (90, 12)\n",
      "Shape of dataframe 553: (44, 12)\n",
      "Shape of dataframe 554: (116, 12)\n",
      "Shape of dataframe 555: (116, 12)\n",
      "Shape of dataframe 556: (116, 12)\n",
      "Shape of dataframe 557: (116, 12)\n",
      "Shape of dataframe 558: (116, 12)\n",
      "Shape of dataframe 559: (116, 12)\n",
      "Shape of dataframe 560: (8, 12)\n",
      "Shape of dataframe 561: (125, 12)\n",
      "Shape of dataframe 562: (116, 12)\n",
      "Shape of dataframe 563: (116, 12)\n",
      "Shape of dataframe 564: (0, 12)\n",
      "Shape of dataframe 565: (44, 12)\n",
      "Shape of dataframe 566: (116, 12)\n",
      "Shape of dataframe 567: (116, 12)\n",
      "Shape of dataframe 568: (85, 12)\n",
      "Shape of dataframe 569: (44, 12)\n",
      "Shape of dataframe 570: (125, 12)\n",
      "Shape of dataframe 571: (116, 12)\n",
      "Shape of dataframe 572: (125, 12)\n",
      "Shape of dataframe 573: (125, 12)\n",
      "Shape of dataframe 574: (116, 12)\n",
      "Shape of dataframe 575: (116, 12)\n",
      "Shape of dataframe 576: (116, 12)\n",
      "Shape of dataframe 577: (116, 12)\n",
      "Shape of dataframe 578: (125, 12)\n",
      "Shape of dataframe 579: (116, 12)\n",
      "Shape of dataframe 580: (35, 12)\n",
      "Shape of dataframe 581: (116, 12)\n",
      "Shape of dataframe 582: (98, 12)\n",
      "Shape of dataframe 583: (27, 12)\n",
      "Shape of dataframe 584: (98, 12)\n",
      "Shape of dataframe 585: (116, 12)\n",
      "Shape of dataframe 586: (35, 12)\n",
      "Shape of dataframe 587: (116, 12)\n",
      "Shape of dataframe 588: (116, 12)\n",
      "Shape of dataframe 589: (116, 12)\n",
      "Shape of dataframe 590: (66, 12)\n",
      "Shape of dataframe 591: (116, 12)\n",
      "Shape of dataframe 592: (30, 12)\n",
      "Shape of dataframe 593: (125, 12)\n",
      "Shape of dataframe 594: (114, 12)\n",
      "Shape of dataframe 595: (98, 12)\n",
      "Shape of dataframe 596: (116, 12)\n",
      "Shape of dataframe 597: (125, 12)\n",
      "Shape of dataframe 598: (97, 12)\n",
      "Shape of dataframe 599: (24, 12)\n",
      "Shape of dataframe 600: (116, 12)\n",
      "Shape of dataframe 601: (125, 12)\n",
      "Shape of dataframe 602: (107, 12)\n",
      "Shape of dataframe 603: (116, 12)\n",
      "Shape of dataframe 604: (114, 12)\n",
      "Shape of dataframe 605: (116, 12)\n",
      "Shape of dataframe 606: (116, 12)\n",
      "Shape of dataframe 607: (35, 12)\n",
      "Shape of dataframe 608: (125, 12)\n",
      "Shape of dataframe 609: (116, 12)\n",
      "Shape of dataframe 610: (44, 12)\n",
      "Shape of dataframe 611: (114, 12)\n",
      "Shape of dataframe 612: (116, 12)\n",
      "Shape of dataframe 613: (10, 12)\n",
      "Shape of dataframe 614: (25, 12)\n",
      "Shape of dataframe 615: (116, 12)\n",
      "Shape of dataframe 616: (116, 12)\n",
      "Shape of dataframe 617: (116, 12)\n",
      "Shape of dataframe 618: (125, 12)\n",
      "Shape of dataframe 619: (29, 12)\n",
      "Shape of dataframe 620: (98, 12)\n",
      "Shape of dataframe 621: (116, 12)\n",
      "Shape of dataframe 622: (125, 12)\n",
      "Shape of dataframe 623: (116, 12)\n",
      "Shape of dataframe 624: (116, 12)\n",
      "Shape of dataframe 625: (116, 12)\n",
      "Shape of dataframe 626: (116, 12)\n",
      "Shape of dataframe 627: (116, 12)\n",
      "Shape of dataframe 628: (116, 12)\n",
      "Shape of dataframe 629: (125, 12)\n",
      "Shape of dataframe 630: (116, 12)\n",
      "Shape of dataframe 631: (125, 12)\n",
      "Shape of dataframe 632: (116, 12)\n",
      "Shape of dataframe 633: (125, 12)\n",
      "Shape of dataframe 634: (125, 12)\n",
      "Shape of dataframe 635: (116, 12)\n",
      "Shape of dataframe 636: (125, 12)\n",
      "Shape of dataframe 637: (125, 12)\n",
      "Shape of dataframe 638: (76, 12)\n",
      "Shape of dataframe 639: (107, 12)\n",
      "Shape of dataframe 640: (27, 12)\n",
      "Shape of dataframe 641: (116, 12)\n",
      "Shape of dataframe 642: (125, 12)\n",
      "Shape of dataframe 643: (116, 12)\n",
      "Shape of dataframe 644: (116, 12)\n",
      "Shape of dataframe 645: (125, 12)\n",
      "Shape of dataframe 646: (35, 12)\n",
      "Shape of dataframe 647: (125, 12)\n",
      "Shape of dataframe 648: (11, 12)\n",
      "Shape of dataframe 649: (116, 12)\n",
      "Shape of dataframe 650: (125, 12)\n",
      "Shape of dataframe 651: (116, 12)\n",
      "Shape of dataframe 652: (125, 12)\n",
      "Shape of dataframe 653: (116, 12)\n",
      "Shape of dataframe 654: (116, 12)\n",
      "Shape of dataframe 655: (116, 12)\n",
      "Shape of dataframe 656: (125, 12)\n",
      "Shape of dataframe 657: (98, 12)\n",
      "Shape of dataframe 658: (125, 12)\n",
      "Shape of dataframe 659: (125, 12)\n",
      "Shape of dataframe 660: (125, 12)\n",
      "Shape of dataframe 661: (16, 12)\n",
      "Shape of dataframe 662: (116, 12)\n",
      "Shape of dataframe 0: (116, 12)\n",
      "Shape of dataframe 1: (44, 12)\n",
      "Shape of dataframe 2: (116, 12)\n",
      "Shape of dataframe 3: (35, 12)\n",
      "Shape of dataframe 4: (116, 12)\n",
      "Shape of dataframe 5: (98, 12)\n",
      "Shape of dataframe 6: (125, 12)\n",
      "Shape of dataframe 7: (35, 12)\n",
      "Shape of dataframe 8: (107, 12)\n",
      "Shape of dataframe 9: (116, 12)\n",
      "Shape of dataframe 10: (116, 12)\n",
      "Shape of dataframe 11: (116, 12)\n",
      "Shape of dataframe 12: (116, 12)\n",
      "Shape of dataframe 13: (116, 12)\n",
      "Shape of dataframe 14: (116, 12)\n",
      "Shape of dataframe 15: (116, 12)\n",
      "Shape of dataframe 16: (116, 12)\n",
      "Shape of dataframe 17: (116, 12)\n",
      "Shape of dataframe 18: (116, 12)\n",
      "Shape of dataframe 19: (44, 12)\n",
      "Shape of dataframe 20: (116, 12)\n",
      "Shape of dataframe 21: (9, 12)\n",
      "Shape of dataframe 22: (116, 12)\n",
      "Shape of dataframe 23: (98, 12)\n",
      "Shape of dataframe 24: (125, 12)\n",
      "Shape of dataframe 25: (116, 12)\n",
      "Shape of dataframe 26: (116, 12)\n",
      "Shape of dataframe 27: (44, 12)\n",
      "Shape of dataframe 28: (98, 12)\n",
      "Shape of dataframe 29: (84, 12)\n",
      "Shape of dataframe 30: (125, 12)\n",
      "Shape of dataframe 31: (125, 12)\n",
      "Shape of dataframe 32: (20, 12)\n",
      "Shape of dataframe 33: (35, 12)\n",
      "Shape of dataframe 34: (116, 12)\n",
      "Shape of dataframe 35: (116, 12)\n",
      "Shape of dataframe 36: (107, 12)\n",
      "Shape of dataframe 37: (125, 12)\n",
      "Shape of dataframe 38: (116, 12)\n",
      "Shape of dataframe 39: (116, 12)\n",
      "Shape of dataframe 40: (35, 12)\n",
      "Shape of dataframe 41: (115, 12)\n",
      "Shape of dataframe 42: (125, 12)\n",
      "Shape of dataframe 43: (107, 12)\n",
      "Shape of dataframe 44: (125, 12)\n",
      "Shape of dataframe 45: (116, 12)\n",
      "Shape of dataframe 46: (98, 12)\n",
      "Shape of dataframe 47: (116, 12)\n",
      "Shape of dataframe 48: (116, 12)\n",
      "Shape of dataframe 49: (116, 12)\n",
      "Shape of dataframe 50: (125, 12)\n",
      "Shape of dataframe 51: (125, 12)\n",
      "Shape of dataframe 52: (115, 12)\n",
      "Shape of dataframe 53: (125, 12)\n",
      "Shape of dataframe 54: (125, 12)\n",
      "Shape of dataframe 55: (125, 12)\n",
      "Shape of dataframe 56: (107, 12)\n",
      "Shape of dataframe 57: (44, 12)\n",
      "Shape of dataframe 58: (116, 12)\n",
      "Shape of dataframe 59: (116, 12)\n",
      "Shape of dataframe 60: (89, 12)\n",
      "Shape of dataframe 61: (116, 12)\n",
      "Shape of dataframe 62: (104, 12)\n",
      "Shape of dataframe 63: (44, 12)\n",
      "Shape of dataframe 64: (98, 12)\n",
      "Shape of dataframe 65: (44, 12)\n",
      "Shape of dataframe 66: (62, 12)\n",
      "Shape of dataframe 67: (98, 12)\n",
      "Shape of dataframe 68: (125, 12)\n",
      "Shape of dataframe 69: (125, 12)\n",
      "Shape of dataframe 70: (107, 12)\n",
      "Shape of dataframe 71: (44, 12)\n",
      "Shape of dataframe 72: (44, 12)\n",
      "Shape of dataframe 73: (115, 12)\n",
      "Shape of dataframe 74: (125, 12)\n",
      "Shape of dataframe 75: (107, 12)\n",
      "Shape of dataframe 76: (125, 12)\n",
      "Shape of dataframe 77: (125, 12)\n",
      "Shape of dataframe 78: (116, 12)\n",
      "Shape of dataframe 79: (14, 12)\n",
      "Shape of dataframe 80: (35, 12)\n",
      "Shape of dataframe 81: (44, 12)\n",
      "Shape of dataframe 82: (116, 12)\n",
      "Shape of dataframe 83: (116, 12)\n",
      "Shape of dataframe 84: (35, 12)\n",
      "Shape of dataframe 85: (125, 12)\n",
      "Shape of dataframe 86: (41, 12)\n",
      "Shape of dataframe 87: (116, 12)\n",
      "Shape of dataframe 88: (125, 12)\n",
      "Shape of dataframe 89: (115, 12)\n",
      "Shape of dataframe 90: (116, 12)\n",
      "Shape of dataframe 91: (24, 12)\n",
      "Shape of dataframe 92: (110, 12)\n",
      "Shape of dataframe 93: (125, 12)\n",
      "Shape of dataframe 94: (116, 12)\n",
      "Shape of dataframe 95: (116, 12)\n",
      "Shape of dataframe 96: (116, 12)\n",
      "Shape of dataframe 97: (35, 12)\n",
      "Shape of dataframe 98: (116, 12)\n",
      "Shape of dataframe 99: (116, 12)\n",
      "Shape of dataframe 100: (107, 12)\n",
      "Shape of dataframe 101: (125, 12)\n",
      "Shape of dataframe 102: (98, 12)\n",
      "Shape of dataframe 103: (116, 12)\n",
      "Shape of dataframe 104: (116, 12)\n",
      "Shape of dataframe 105: (125, 12)\n",
      "Shape of dataframe 106: (0, 12)\n",
      "Shape of dataframe 107: (116, 12)\n",
      "Shape of dataframe 108: (116, 12)\n",
      "Shape of dataframe 109: (116, 12)\n",
      "Shape of dataframe 110: (98, 12)\n",
      "Shape of dataframe 111: (125, 12)\n",
      "Shape of dataframe 112: (116, 12)\n",
      "Shape of dataframe 113: (31, 12)\n",
      "Shape of dataframe 114: (125, 12)\n",
      "Shape of dataframe 115: (116, 12)\n",
      "Shape of dataframe 116: (116, 12)\n",
      "Shape of dataframe 117: (2, 12)\n",
      "Shape of dataframe 118: (116, 12)\n",
      "Shape of dataframe 119: (116, 12)\n",
      "Shape of dataframe 120: (116, 12)\n",
      "Shape of dataframe 121: (116, 12)\n",
      "Shape of dataframe 122: (116, 12)\n",
      "Shape of dataframe 123: (116, 12)\n",
      "Shape of dataframe 124: (116, 12)\n",
      "Shape of dataframe 125: (125, 12)\n",
      "Shape of dataframe 126: (116, 12)\n",
      "Shape of dataframe 127: (35, 12)\n",
      "Shape of dataframe 128: (116, 12)\n",
      "Shape of dataframe 129: (125, 12)\n",
      "Shape of dataframe 130: (27, 12)\n",
      "Shape of dataframe 131: (125, 12)\n",
      "Shape of dataframe 132: (116, 12)\n",
      "Shape of dataframe 133: (116, 12)\n",
      "Shape of dataframe 134: (44, 12)\n",
      "Shape of dataframe 135: (107, 12)\n",
      "Shape of dataframe 136: (125, 12)\n",
      "Shape of dataframe 137: (125, 12)\n",
      "Shape of dataframe 138: (116, 12)\n",
      "Shape of dataframe 139: (29, 12)\n",
      "Shape of dataframe 140: (116, 12)\n",
      "Shape of dataframe 141: (125, 12)\n",
      "Shape of dataframe 142: (125, 12)\n",
      "Shape of dataframe 143: (125, 12)\n",
      "Shape of dataframe 144: (125, 12)\n",
      "Shape of dataframe 145: (0, 12)\n",
      "Shape of dataframe 146: (34, 12)\n",
      "Shape of dataframe 147: (116, 12)\n",
      "Shape of dataframe 148: (125, 12)\n",
      "Shape of dataframe 149: (125, 12)\n",
      "Shape of dataframe 150: (35, 12)\n",
      "Shape of dataframe 151: (35, 12)\n",
      "Shape of dataframe 152: (98, 12)\n",
      "Shape of dataframe 153: (44, 12)\n",
      "Shape of dataframe 154: (116, 12)\n",
      "Shape of dataframe 155: (71, 12)\n",
      "Shape of dataframe 156: (116, 12)\n",
      "Shape of dataframe 157: (116, 12)\n",
      "Shape of dataframe 158: (125, 12)\n",
      "Shape of dataframe 159: (116, 12)\n",
      "Shape of dataframe 160: (125, 12)\n",
      "Shape of dataframe 161: (107, 12)\n",
      "Shape of dataframe 162: (116, 12)\n",
      "Shape of dataframe 163: (125, 12)\n",
      "Shape of dataframe 164: (98, 12)\n",
      "Shape of dataframe 165: (107, 12)\n"
     ]
    }
   ],
   "source": [
    "# for i, df in enumerate(train_data):\n",
    "#     print(f\"Shape of dataframe {i}: {df.shape}\")\n",
    "    \n",
    "# for i, df in enumerate(test_data):\n",
    "#     print(f\"Shape of dataframe {i}: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c19b4041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dataframes in dataframe_list:  829\n",
      "Number of dataframes in training data:  663\n",
      "Number of dataframes in testing data:  166\n"
     ]
    }
   ],
   "source": [
    "# print(\"Number of dataframes in dataframe_list: \", len(dataframe_list_1))\n",
    "# print(\"Number of dataframes in training data: \", len(train_data))\n",
    "# print(\"Number of dataframes in testing data: \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e3384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(train_data) == 0:\n",
    "#     print(\"No CSV files found in the training data directory\")\n",
    "#     exit()\n",
    "\n",
    "# if len(test_data) == 0:\n",
    "#     print(\"No CSV files found in the testing data directory\")\n",
    "#     exit()\n",
    "\n",
    "# # Extract the features and labels from the training and testing data\n",
    "# X_train = np.array([df.iloc[:, :-1].values for df in train_data])\n",
    "# y_train = np.array([df.iloc[0, -1] for df in train_data])\n",
    "# X_test = np.array([df.iloc[:, :-1].values for df in test_data])\n",
    "# y_test = np.array([df.iloc[0, -1] for df in test_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3b755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the features and labels from the training and testing data\n",
    "# X_train = np.array([df[:, :-1] for df in train_data])\n",
    "# y_train = np.array([df[0, -1] for df in train_data])\n",
    "# X_test = np.array([df[:, :-1] for df in test_data])\n",
    "# y_test = np.array([df[0, -1] for df in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d29061a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# svm = SVC(kernel='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07fab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "380f02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import csv\n",
    "\n",
    "# folder_path = \"/Users/shreya/606 Capstone/mediaPipe_keypoints_data_UPD\"\n",
    "# file_list = os.listdir(folder_path)\n",
    "\n",
    "# data_list = []\n",
    "# for file_name in file_list:\n",
    "#     if file_name.endswith('.csv'):\n",
    "#         file_path = os.path.join(folder_path, file_name)\n",
    "#         with open(file_path, 'r') as csv_file:\n",
    "#             csv_reader = csv.reader(csv_file)\n",
    "#             data_array = []\n",
    "#             for row in csv_reader:\n",
    "#                 data_array.append(row)\n",
    "#             data_list.append(data_array)\n",
    "\n",
    "# #print(data_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98545258",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fd3e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d317f46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
