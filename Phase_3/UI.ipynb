{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28acb19d",
   "metadata": {},
   "source": [
    "## UI for CAUT Deception Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2defcb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mediapipe processing 1 video\n",
    "import os\n",
    "import cv2\n",
    "import traceback\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import math\n",
    "\n",
    "from MediaPipe_Processing_single_video import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb28482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openFace processing one video\n",
    "def process_video_openface(vid_path):\n",
    "    test_video_path = vid_path\n",
    "    video_prediction = detector.detect_video(test_video_path, skip_frames=24)\n",
    "    vid_mean = video_prediction.mean()\n",
    "    vid_mean_df = vid_mean.to_frame()\n",
    "    vid_mean_df = vid_mean_df.transpose()\n",
    "    vid_mean_df = vid_mean_df[['AU01','AU02','AU04','AU05','AU06','AU07','AU09','AU10','AU11','AU12','AU14','AU15','AU17','AU20','AU23','AU24','AU25','AU26','AU28','AU43','anger','disgust','fear','happiness','sadness','surprise','neutral']]\n",
    "    return vid_mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cee9731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions for the video\n",
    "import _pickle as cPickle\n",
    "\n",
    "def DetectDeception(vid_path,mode):\n",
    "    if mode == \"OpenFace\":\n",
    "        new_X = process_video_openface(vid_path)\n",
    "        with open('C:\\\\Work\\\\606Capstone\\\\Video_chunks\\\\Models\\\\OpenFaceAverage_RFR.pickle', 'rb') as f:\n",
    "            rf = cPickle.load(f)\n",
    "    else:\n",
    "        new_X = process_video_mediapipe(vid_path, required_fps=90)\n",
    "        with open('C:\\\\Work\\\\606Capstone\\\\Video_chunks\\\\Models\\\\MediaPipeSequential_RFR.pickle', 'rb') as f:\n",
    "            rf = cPickle.load(f)\n",
    "\n",
    "    preds = rf.predict(new_X)\n",
    "    return preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions for the video\n",
    "from utils import CautDataloaderRegular\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "    \n",
    "def RFR_Model(vid_path,mode):\n",
    "    if mode == \"OpenFace\":\n",
    "        approach_type = \"average\"\n",
    "        data_dir = \"C:\\\\Work\\\\606Capstone\\\\Video_chunks\\\\Excel\\\\\"\n",
    "    else:\n",
    "        approach_type = \"sequential\"\n",
    "        data_dir = \"C:\\\\Work\\\\606Capstone\\\\Video_chunks\\\\MediaPipe\\\\\"\n",
    "        \n",
    "    X_y_data = CautDataloaderRegular.get_X_y_TrainTest(csv_path=\"C:\\\\Work\\\\606Capstone\\\\Video_chunks\\\\CSV\\\\\",\n",
    "                                                       data_dir=data_dir,\n",
    "                                                       data_mode=mode,\n",
    "                                                       approach_type=approach_type,\n",
    "                                                       verbose=True)\n",
    "    \n",
    "    X_train, y_train = X_y_data[0], X_y_data[1]\n",
    "    \n",
    "    if(mode == \"OpenFace\"):\n",
    "        y_video = process_video_openface(vid_path)\n",
    "    else:\n",
    "        video_mediapipe = process_video_mediapipe(vid_path, required_fps=90)\n",
    "        y_video = video_mediapipe.reshape((-1, video_mediapipe.shape[-1]))\n",
    "    \n",
    "    # Setup model:\n",
    "    #fitting and evaluating\n",
    "    print(f\"Creating the model\")\n",
    "    rf = RandomForestClassifier(n_estimators=120)\n",
    "    \n",
    "    # fit the model:\n",
    "    print(f\"Fitting the model\")\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # predict on test data:\n",
    "    print(f\"Shape of \")\n",
    "    y_pred = rf.predict(y_video)\n",
    "    print(f\"Predictions: {y_pred}\")\n",
    "    return y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac658afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the graph for emotions\n",
    "def Plot_Emotions(vid_path):\n",
    "    test_video_path = vid_path\n",
    "    video_prediction = detector.detect_video(test_video_path, skip_frames=24)\n",
    "    vid_mean = video_prediction.mean()\n",
    "    vid_mean_df = vid_mean.to_frame()\n",
    "    vid_mean_df = vid_mean_df.transpose()\n",
    "    vid_to_plot = vid_mean_df[['anger','disgust','fear','happiness','sadness','surprise','neutral']].transpose().reset_index()\n",
    "    trace = go.Bar(x=vid_to_plot[vid_to_plot.columns[0]], y=vid_to_plot[vid_to_plot.columns[1]], \n",
    "               marker={'color': vid_to_plot[vid_to_plot.columns[1]], 'colorscale': 'Blugrn'})\n",
    "    layout = go.Layout(title='Emotions in the Video', width=500, height=450)\n",
    "    fig = go.Figure(data=[trace], layout=layout)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d624e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feat.detector.Detector(face_model=retinaface, landmark_model=mobilefacenet, au_model=xgb, emotion_model=resmasknet, facepose_model=img2pose)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#detector for Openface\n",
    "from tqdm import tqdm\n",
    "from feat import Detector\n",
    "\n",
    "detector = Detector()\n",
    "detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "962af782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Dash is running on http://127.0.0.1:8050/\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.12s/it]\n",
      "C:\\Users\\hinal\\AppData\\Local\\Temp/ipykernel_11516/405049184.py:5: FutureWarning:\n",
      "\n",
      "Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import plotly.graph_objs as go'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import plotly.graph_objs as go'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import plotly.graph_objs as go'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------\n",
      "Video Capture Path: assets\\trial_truth_043_004.mp4\n"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html, Input, Output, State\n",
    "import dash_daq as daq\n",
    "import base64\n",
    "import os\n",
    "from werkzeug.utils import secure_filename\n",
    "\n",
    "ss = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "app = dash.Dash(__name__, external_stylesheets=ss, assets_external_path='./assets/')\n",
    "\n",
    "ASSET_DIR = \"assets\"\n",
    "\n",
    "app.layout = html.Div([\n",
    "    #heading\n",
    "    html.H1(\"DECEPTION DETECTION\", style={'textAlign': 'center', 'font-size': '30px'}),\n",
    "    \n",
    "    #column 1\n",
    "    html.Div([\n",
    "      html.Label(\"Select an option:\", style={'font-size': '24px'}),\n",
    "        dcc.RadioItems(\n",
    "            id='video-selector',\n",
    "            options=[\n",
    "                {'label': 'Select a video from dropdown', 'value': 'dropdown'},\n",
    "                {'label': 'Upload a video', 'value': 'upload'},\n",
    "            ]\n",
    "        ),\n",
    "        html.Div([\n",
    "            dcc.Dropdown(id='file-list',style={'width': '250px'}),\n",
    "        ], id=\"dropdown-div\", style={'display': 'none'}),\n",
    "        html.Div([\n",
    "            dcc.Upload(\n",
    "            id='upload-video',\n",
    "            children=html.Div([\n",
    "                'Drag and Drop or ',\n",
    "                html.A('Select a Video')\n",
    "            ]),\n",
    "            style={\n",
    "                'width': '100%',\n",
    "                'height': '60px',\n",
    "                'lineHeight': '60px',\n",
    "                'borderWidth': '1px',\n",
    "                'borderStyle': 'dashed',\n",
    "                'borderRadius': '5px',\n",
    "                'textAlign': 'center',\n",
    "                'margin': '10px'\n",
    "            },\n",
    "            multiple=False\n",
    "        ),\n",
    "        ], id=\"upload-div\", style={'display': 'none'}),  \n",
    "    ], style={'display': 'inline-block','vertical-align': 'top'}),\n",
    "    html.Br(),\n",
    "    html.Div(id='output-graph'),\n",
    "    \n",
    "    #column 2\n",
    "    html.Div([\n",
    "      html.Div([\n",
    "            html.Div([\n",
    "                html.Video(id='video-player', controls=True, \n",
    "                           style={\n",
    "                                \"width\": \"50%\",\n",
    "                               \"height\": \"65%\",# set the width of the video frame\n",
    "                                \"position\": \"absolute\",  # set the position to absolute\n",
    "                                \"left\": \"40%\",  # set the left margin to center the video\n",
    "                                \"top\": \"50px\"  # set the top margin to 50 pixels from the top\n",
    "                                }\n",
    "                          )\n",
    "            ])\n",
    "        ], id='video-div', style={'display': 'none'}),\n",
    "        html.Div([\n",
    "            html.Label('MediaPipe', style={\n",
    "                'display': 'block',\n",
    "                'text-align': 'center',\n",
    "                'position': 'absolute',\n",
    "                'left': '93%',\n",
    "                'top': '75px',\n",
    "                'font-size': '18px'\n",
    "            }),\n",
    "            daq.BooleanSwitch(\n",
    "                id='my-boolean-switch', \n",
    "                on=False, \n",
    "                color='#1c4a60', \n",
    "                vertical=True, \n",
    "                labelPosition='bottom',\n",
    "                style={\n",
    "                    'position': 'absolute',\n",
    "                    'left': '93%',\n",
    "                    'top': '110px'\n",
    "                }\n",
    "            ),\n",
    "            html.Label('OpenFace', style={\n",
    "                'display': 'block',\n",
    "                'text-align': 'center',\n",
    "                'position': 'absolute',\n",
    "                'left': '93%',\n",
    "                'top': '150px',\n",
    "                'font-size': '18px'\n",
    "            })\n",
    "        ], id='toggle-div', style={'display': 'none'}),\n",
    "        html.Div([\n",
    "            html.Button('DETECT', id='play-button', style={\n",
    "                                \"position\": \"absolute\",\n",
    "                                \"left\": \"60%\",\n",
    "                                \"top\": \"550px\"\n",
    "                                #'background-color': '#AFE1AF'\n",
    "                                })\n",
    "        ], id=\"detect-div\", style={'font-size': '24px', 'display': 'none'}),\n",
    "        html.Div(id='output', style={\n",
    "                                \"position\": \"absolute\",\n",
    "                                \"left\": \"55%\",\n",
    "                                \"top\": \"600px\", \n",
    "                                'font-size': '24px'\n",
    "                                })  \n",
    "    ],style={'display': 'inline-block','vertical-align': 'top','margin-left': '100px'})\n",
    "])\n",
    "\n",
    "# Define the callback to list the files in the asset folder\n",
    "@app.callback(\n",
    "    Output('file-list', 'options'),\n",
    "    [Input('file-list', 'contents')])\n",
    "def update_file_list(contents):\n",
    "    # List the files in the asset folder\n",
    "    file_list = os.listdir(ASSET_DIR)\n",
    "    options = [{'label': f, 'value': f} for f in file_list]\n",
    "    return options\n",
    "\n",
    "#callback to display the video block once source path is updated\n",
    "@app.callback(\n",
    "    Output('video-div', 'style'),\n",
    "    [Input('video-player', 'src')])\n",
    "def update_video_src(value):\n",
    "    if value:\n",
    "        return {\"display\" : \"inline-block\"}\n",
    "    else:\n",
    "        return {\"display\" : \"none\"}\n",
    "    \n",
    "#callback to display the toggle switch\n",
    "@app.callback(\n",
    "    Output('toggle-div', 'style'),\n",
    "    [Input('video-player', 'src')])\n",
    "def update_video_src(value):\n",
    "    if value:\n",
    "        return {\"display\" : \"inline-block\"}\n",
    "    else:\n",
    "        return {\"display\" : \"none\"}\n",
    "\n",
    "#callback to update the path of the video\n",
    "@app.callback(\n",
    "    Output('video-player', 'src'),\n",
    "    [Input('video-selector', 'value'),\n",
    "     Input('file-list', 'value'),\n",
    "     Input('upload-video', 'contents')],\n",
    "    State('upload-video', 'filename')\n",
    ")\n",
    "def upload_file(value, filelistvalue, content, filename):\n",
    "    if value == \"dropdown\":\n",
    "        if filelistvalue:\n",
    "            src = os.path.join(ASSET_DIR, secure_filename(filelistvalue))\n",
    "            return src\n",
    "        else:\n",
    "            return \"\"\n",
    "    else:\n",
    "        if content is not None:\n",
    "            video_path = os.path.join(ASSET_DIR, secure_filename(filename))\n",
    "            content_type, content_string = content.split(',')\n",
    "            decoded_content = base64.b64decode(content_string)\n",
    "            with open(video_path, 'wb') as f:\n",
    "                f.write(decoded_content)\n",
    "            return video_path\n",
    "        else:\n",
    "            return \"\"\n",
    "        \n",
    "#callback to either display dropdown or display upload option\n",
    "@app.callback(\n",
    "    [Output('dropdown-div', 'style'),Output('upload-div', 'style')],\n",
    "    [Input('video-selector', 'value')]\n",
    ")\n",
    "def update_video_src(value):\n",
    "    if value == \"dropdown\":\n",
    "        return ({\"display\" : \"inline-block\"},{\"display\" : \"none\"})\n",
    "    else:\n",
    "        return ({\"display\" : \"none\"},{\"display\" : \"inline-block\"})\n",
    "    \n",
    "#call back for displaying the graph\n",
    "@app.callback(\n",
    "    Output('output-graph', 'children'),\n",
    "    [Input('video-player', 'src')]\n",
    ")\n",
    "def update_graph(input_value):\n",
    "    fig = Plot_Emotions(input_value)\n",
    "    return dcc.Graph(figure=fig)\n",
    "\n",
    "\n",
    "# Define the callback for the detect button\n",
    "@app.callback(\n",
    "    Output('output', 'children'),\n",
    "    [Input('play-button', 'n_clicks'),\n",
    "    Input('video-player', 'src'),\n",
    "    Input('my-boolean-switch', 'on')])\n",
    "def play_video(n_clicks, src, value):\n",
    "    if n_clicks is None:\n",
    "        return f\"\"\n",
    "    else:\n",
    "        if value:\n",
    "            detector = \"MediaPipe\"\n",
    "        else:\n",
    "            detector = \"OpenFace\"\n",
    "        v = DetectDeception(src, detector)\n",
    "        if v:\n",
    "            return f\"The person is lying.\"\n",
    "        else:\n",
    "            return f\"The person is saying the truth.\"\n",
    "    return src\n",
    "\n",
    "#callback to display the detect button\n",
    "@app.callback(\n",
    "    Output('detect-div', 'style'),\n",
    "    [Input('video-player', 'src')])\n",
    "def update_video_src(value):\n",
    "    if value:\n",
    "        return {'textAlign': 'center',\"display\" : \"block\"}\n",
    "    else:\n",
    "        return {'textAlign': 'center',\"display\" : \"none\"}\n",
    "    \n",
    "# Reset n_clicks when a different video is selected\n",
    "@app.callback(\n",
    "    Output('play-button', 'n_clicks'),\n",
    "    [Input('video-player', 'src')]\n",
    ")\n",
    "def reset_n_clicks(src):\n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, use_reloader=False)\n",
    "    #app.run_server(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
